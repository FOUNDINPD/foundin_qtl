{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to prep FOUNDIN-PD modality for a specific day\n",
    "will output a scaled and covariate adjusted file for the day and modality specified; notebook expects the split quant by day notebook has already been run\n",
    "\n",
    "- this notebook is still very duplicative and the step and code included in the split quants by day notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, read_hdf, DataFrame, read_pickle\n",
    "import nb_util_funcs as nuf\n",
    "from random import sample\n",
    "from seaborn import distplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebooks variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "modality = ''\n",
    "day = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort = 'foundin'\n",
    "set_name = f'{cohort}_{day}_{modality}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/home/jupyter/foundin_qtl'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "public_dir = f'{wrk_dir}/public'\n",
    "\n",
    "# in files\n",
    "quants_file = f'{quants_dir}/{set_name}.hdf5'\n",
    "covariates_file = f'{info_dir}/{cohort}_{modality}_sample_info.csv'\n",
    "if modality == 'ATAC':\n",
    "    features_file = f'{quants_dir}/{cohort}_consensus_peaks.saf'\n",
    "elif modality == 'METH':\n",
    "    features_file = f'{quants_dir}/EPIC_annotation_hg38.txt'    \n",
    "elif modality.startswith('PDUI'):\n",
    "    features_file = f'{quants_dir}/{cohort}_{modality}.features.csv'\n",
    "elif modality == 'RNAB' or modality.startswith('SCRN'):\n",
    "    features_file = f'{public_dir}/gencode_v29.lncipedia_v5_2_hc.annotation.pkl'\n",
    "elif modality == 'CIRC':\n",
    "    features_file = f'{quants_dir}/circRNA_genomicRegionList.tsv'    \n",
    "\n",
    "# out files\n",
    "umap_covs_file = f'{info_dir}/{set_name}.umap.covs.csv'\n",
    "scaled_file = f'{quants_dir}/{set_name}.scaled.hdf5'\n",
    "adj_quants_file = f'{quants_dir}/{set_name}.scaled.adj.hdf5'\n",
    "tnsrqtl_pheno_file = f'{quants_dir}/{set_name}.scaled.adj.bed.gz'\n",
    "\n",
    "# constants\n",
    "if modality == 'METH':\n",
    "    min_detection_rate = 0.75\n",
    "else:\n",
    "    min_detection_rate = 0.25\n",
    "if modality.startswith('SCRN') or modality in ['PDUI-DA', 'PDUI-iDA']:\n",
    "    size_covariate='EstimatedNumberofCells'\n",
    "else:\n",
    "    size_covariate='DAn'    \n",
    "DEBUG = False\n",
    "low_var_quartile = '75%'\n",
    "dpi_value = 50\n",
    "\n",
    "other_id_columns = ['sampleid', 'cdi', 'PPMI_ID', 'DZNE_Barcode', 'DZNE_ID', \n",
    "                    'participant_id', 'wgsid', 'PATNO', 'Barcode_LNG', \n",
    "                    'Barcode_DZNE', 'Alternate MRN', 'IID', 'FID']\n",
    "exclude_addl_info_cols = ['data_split', 'ENSG00000188906.15', 'ENSG00000131979.18',\n",
    "                          'ENSG00000129003.17', 'ENSG00000069329.17', \n",
    "                          'ENSG00000177628.15', 'ENSG00000158828.7',\n",
    "                          'ENSG00000145335.15', 'ENSG00000164535.14', \n",
    "                          'ENSG00000165092.12', 'ENSG00000147133.15',\n",
    "                          'ENSG00000155961.4']\n",
    "# to match geno's use PPMI3966 Batch3\n",
    "replace_id_dict = {'PPMI3966B3': 'PPMI3966'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the quantified features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_hdf(quants_file)\n",
    "print(quants_df.shape)\n",
    "\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split name index to find info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts = quants_df.index.str.split('_', expand=True).to_frame()\n",
    "id_parts.columns = ['assay', 'sampleid', 'day']\n",
    "\n",
    "id_parts['assayid'] = quants_df.index.values\n",
    "print(id_parts.shape)\n",
    "if DEBUG:\n",
    "    display(id_parts.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get counts by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts['day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### capture the assayid to wgsid for formatting phenotypes for use with wgs genotypes later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = id_parts[['sampleid', 'assayid']]\n",
    "id_map['sampleid'] = id_map['sampleid'].replace(replace_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = read_csv(covariates_file, index_col=0)\n",
    "# drop any duplicated indices\n",
    "print(covs_df.shape)\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(quants_df.index) - set(covs_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(id_parts['sampleid']) - set(covs_df['sampleid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for further analysis remove the ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covs_df.shape)\n",
    "cols_to_keep = set(covs_df.columns) - set(other_id_columns) - set(exclude_addl_info_cols)\n",
    "covs_df = covs_df[cols_to_keep]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load feature annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if modality == 'ATAC':\n",
    "    features_df = read_csv(features_file, sep='\\t')\n",
    "    features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']\n",
    "elif modality == 'METH':\n",
    "    features_df = read_csv(features_file, sep='\\t', header=None)\n",
    "    features_df.columns = ['Chr', 'start', 'end', 'feature']\n",
    "elif modality.startswith('PDUI'):\n",
    "    features_df = read_csv(features_file)\n",
    "    features_df = features_df.rename(columns={'Loci': 'feature'})\n",
    "elif modality == 'CIRC':\n",
    "    features_df = read_csv(features_file, sep='\\t')\n",
    "    features_df = features_df.rename(columns={'circRNA_ID': 'feature', \n",
    "                                              'chr': 'chrom', \n",
    "                                              'circRNA_start': 'start', \n",
    "                                              'circRNA_end': 'end'})    \n",
    "elif modality == 'RNAB' or modality.startswith('SCRN'):\n",
    "    features_df = read_pickle(features_file)\n",
    "    # features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']\n",
    "    # drop the ont and tag columns\n",
    "    discard_cols = features_df.columns[(features_df.columns.str.startswith('ont')) |\n",
    "                                       (features_df.columns.str.startswith('tag')) | \n",
    "                                       (features_df.columns.str.startswith('havana_')) |                                       \n",
    "                                       (features_df.columns.str.startswith('gene_alias')) | \n",
    "                                       (features_df.columns.str.startswith('transcript_alias'))]\n",
    "    features_df = features_df.drop(columns=discard_cols)\n",
    "    # subset to just 'gene' features\n",
    "    features_df = features_df.loc[features_df.feature == 'gene']\n",
    "    # now drop existing feature col so we can use that name\n",
    "    features_df = features_df.drop(columns=['feature'])\n",
    "    if modality == 'RNAB':\n",
    "        features_df = features_df.rename(columns={'seqname': 'chrom', 'gene_id': 'feature'})    \n",
    "    elif modality.startswith('SCRN'):\n",
    "        features_df = features_df.rename(columns={'seqname': 'chrom', 'gene_name': 'feature'})\n",
    "    \n",
    "print(f'features shape {features_df.shape}')\n",
    "if DEBUG:\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find IDs for features on sex chromosomes, for dropping later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_chr_feature_ids = features_df.loc[features_df.chrom\n",
    "                                      .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "print(len(sex_chr_feature_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373â€“84.\n",
    "sex_genes = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "\n",
    "if modality == 'ATAC':\n",
    "    sex_specific_features = ['chrX_73852329_73852963', 'chrY_2841364_2842239', \n",
    "                             'chrY_19744015_19745452', 'chrY_13478234_13480597', \n",
    "                             'chrY_12904296_12906267', 'chrY_12661424_12663659']\n",
    "elif modality == 'METH':\n",
    "    sex_specific_features = features_df.loc[features_df['Chr']\n",
    "                                          .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "elif modality.startswith('PDUI'):\n",
    "    sex_features = features_df.loc[features_df.Gene.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()\n",
    "elif modality == 'RNAB':\n",
    "    sex_features = features_df.loc[features_df.gene_name.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()\n",
    "elif modality == 'CIRC':\n",
    "    sex_specific_features = ['chrX:73852031|73852204', 'chrX:73826115|73837503', \n",
    "                             'chrY:2845670|2854771', 'chrY:2865189|2866886', \n",
    "                             'chrY:2854744|2865182', 'chrY:2890914|2891101', \n",
    "                             'chrY:2847677|2847984', 'chrY:2854733|2865176', \n",
    "                             'chrY:19739528|19741857', 'chrY:13251002|13369349', \n",
    "                             'chrY:13323555|13378010', 'chrY:13369256|13400051', \n",
    "                             'chrY:13393859|13450820', 'chrY:13410993|13470229', \n",
    "                             'chrY:12909360|12913062', 'chrY:12912963|12914649', \n",
    "                             'chrY:12912963|12914982', 'chrY:12909363|12913062', \n",
    "                             'chrY:12909360|12914649', 'chrY:12707760|12709543', \n",
    "                             'chrY:12709279|12709543', 'chrY:12716791|12841133', \n",
    "                             'chrY:12735612|12739629', 'chrY:12738157|12758642']    \n",
    "elif modality.startswith('SCRN'):\n",
    "    sex_features = features_df.loc[features_df.feature.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()    \n",
    "else:\n",
    "    sex_specific_features = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "sex_features_present = list(set(sex_specific_features) & set(quants_df.columns))\n",
    "print(f'found {len(sex_features_present)} sex features: \\n{sex_features_present}')\n",
    "quants_sex_df = quants_df[sex_features_present].copy()\n",
    "print(f'sex features matrix shape {quants_sex_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sex_umap_df = nuf.generate_umap_covs_df(quants_sex_df, covs_df)\n",
    "nuf.plot_umap_clusters(sex_umap_df, hue_cov='sex', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate, plot detection rates and subset well detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, min_detection_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize the dataset using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_scaled_df = nuf.scale_dataframe(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check transformation for random feature\n",
    "nuf.plot_trnsfrm_effect_example(quants_df, traits_scaled_df,\n",
    "                                bf_label=modality, \n",
    "                                af_label='quantile transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled, well detected data for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.write_df_to_hdf(traits_scaled_df, scaled_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate covariates from variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude low variance features from covariate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_var_df = nuf.exclude_low_var_features(traits_scaled_df, \n",
    "                                             quartile_to_drop=low_var_quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_features = set(quants_var_df.columns) - (set(sex_specific_features))\n",
    "print(len(variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### not going to use PCs but take a look at PCA anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_df = nuf.generate_pca(quants_var_df[variance_features], plot_variance=True)\n",
    "print(pcs_df.shape)\n",
    "if DEBUG:\n",
    "    display(pcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pcs_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = ['PC_0', 'PC_1', 'PC_2']\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pca_pair(pcs_df, 'PC_0', 'PC_1', hue_cov='Batch', size_cov=size_covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate unknown covariates and see if know covariates are source of variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = nuf.generate_umap_covs_df(quants_var_df[variance_features], covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = nuf.pps_predict_targets(umap_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "if len(covs_to_check) > 0:\n",
    "    umap_dums_covs_df = nuf.dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                      set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df)\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot umap of with known covariates of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='Batch', size_cov=size_covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep created covars and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the covariates\n",
    "umap_covs_df = nuf.scale_dataframe(umap_df[covs_target_list])\n",
    "# now save the covariates\n",
    "umap_covs_df.to_csv(umap_covs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust the scaled data by the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see in df's have same indices\n",
    "if not traits_scaled_df.index.equals(umap_covs_df.index):\n",
    "    print('indices are not equal re-index')\n",
    "    # umap_covs_df.reindex(traits_scaled_df.index)\n",
    "    shared_indices = traits_scaled_df.index.intersection(umap_covs_df.index)\n",
    "    traits_scaled_df = traits_scaled_df.loc[shared_indices,]\n",
    "    umap_covs_df = umap_covs_df.loc[shared_indices,]    \n",
    "    \n",
    "traits_scaled_df.index.equals(umap_covs_df.index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "residuals_df, cov_scores_df = nuf.covariate_residuals(traits_scaled_df, umap_covs_df)\n",
    "\n",
    "#take a peek at the data\n",
    "print(f'residuals shape {residuals_df.shape}')\n",
    "print(f'scores shape {cov_scores_df.shape}')\n",
    "if DEBUG:\n",
    "    display(cov_scores_df.head())\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the covariates model scores\n",
    "print(cov_scores_df.describe())\n",
    "# look at the distribution of covariate model scores, \n",
    "# ie get a sense any feature driven by covariates\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': dpi_value}):\n",
    "    plt.style.use('seaborn-bright')\n",
    "    distplot(cov_scores_df['score'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove any features that had more than 75% score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = cov_scores_df[cov_scores_df.score > 0.75].index.values\n",
    "keep_features = list(set(residuals_df.columns) - set(drop_features))\n",
    "residuals_df = residuals_df[keep_features]\n",
    "cov_scores_df = cov_scores_df.loc[cov_scores_df.index.isin(keep_features)]\n",
    "print(len(drop_features))\n",
    "print(len(keep_features))\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "nuf.write_df_to_hdf(residuals_df, adj_quants_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at the scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find feature with largest score\n",
    "large_adj_trait = cov_scores_df.loc[cov_scores_df['score'] == max(cov_scores_df['score'])]\n",
    "print(large_adj_trait)\n",
    "large_adj_traid_id = large_adj_trait.index.values[0]\n",
    "\n",
    "# spot check same feature with largest adjustment effect\n",
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df, large_adj_traid_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the post scaled and covariate adjusted umap variables correlated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = nuf.generate_umap_covs_df(residuals_df, covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = nuf.pps_predict_targets(umap_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='Batch', size_cov=size_covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since switching to tensorQTL can just use one large transcriptome pheno bed instead of per chrom pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get feature annots for present features\n",
    "feature_present_df = features_df.loc[features_df['feature'].isin(residuals_df.columns)]\n",
    "print(f'features present shape {feature_present_df.shape}')\n",
    "# tensorQTL pheno bed is rows = features and columns = samples\n",
    "# where first four columns are chr, start, end, phenotype_id, then sample1 ... sampleN\n",
    "\n",
    "# create dict for renaming columns (samples) from assayid to geno_id\n",
    "sample_col_dict = id_map.set_index('assayid').to_dict()['sampleid']\n",
    "\n",
    "# transpose the residuals df from sample x feature to feature x sample\n",
    "tresiduals_df = residuals_df.transpose()\n",
    "\n",
    "# modify annots\n",
    "if modality == 'METH':\n",
    "    feature_present_df = feature_present_df.rename(columns={'Chr': 'chr'})\n",
    "else:\n",
    "    feature_present_df = feature_present_df.rename(columns={'chrom': 'chr'})\n",
    "feature_present_df['end'] = feature_present_df['start'] + 1\n",
    "print(f'features presnt shape {feature_present_df.shape}')\n",
    "feature_present_df = feature_present_df.drop_duplicates(subset=['feature'], \n",
    "                                                        keep='first', \n",
    "                                                        ignore_index=True)\n",
    "feature_present_df = feature_present_df.set_index('feature', drop=False)\n",
    "feature_present_df = feature_present_df.reindex(tresiduals_df.index)\n",
    "\n",
    "# insert the feature annots\n",
    "tresiduals_df.insert( 0, column='chr', value=feature_present_df['chr'])\n",
    "tresiduals_df.insert( 1, column='start', value=feature_present_df['start'])\n",
    "tresiduals_df.insert( 2, column='end', value=feature_present_df['end'])\n",
    "# METH, PDUI or RNAB\n",
    "tresiduals_df.insert( 3, column='phenotype_id', value=feature_present_df['feature'])\n",
    "\n",
    "# if there are any features that were in quants but not feature annots\n",
    "# remove these with missing positions\n",
    "tresiduals_df = tresiduals_df.loc[~tresiduals_df['chr'].isna()]\n",
    "# make the positions ints instead of floats\n",
    "tresiduals_df['start'] = tresiduals_df['start'].astype('int64')\n",
    "tresiduals_df['end'] = tresiduals_df['end'].astype('int64')\n",
    "\n",
    "# now rename sample ids in columns\n",
    "tresiduals_df = tresiduals_df.rename(columns=sample_col_dict)\n",
    "\n",
    "tresiduals_df.to_csv(tnsrqtl_pheno_file, index=False, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
