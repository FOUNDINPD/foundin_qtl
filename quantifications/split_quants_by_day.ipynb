{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to prep FOUNDIN-PD modalities for analyses\n",
    "will output a scaled and covariate adjusted file for full dataset; ie across days\n",
    "will also output unprepped data just split by differentiation day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, read_pickle, DataFrame\n",
    "from dask.dataframe import read_csv as dd_read_csv\n",
    "import nb_util_funcs as nuf\n",
    "# from numpy import cumsum\n",
    "import concurrent.futures\n",
    "from random import sample\n",
    "from seaborn import distplot\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.multitest as smm\n",
    "from scipy.stats import f_oneway\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebooks variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "modality = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort = 'foundin'\n",
    "set_name = f'{cohort}_daALL_{modality}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = f'/home/gibbsr/working/foundin/foundin_qtl'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "\n",
    "# in files\n",
    "if modality == 'PDUI':\n",
    "    quants_file = f'{quants_dir}/{set_name}.csv'\n",
    "    features_file = f'{quants_dir}/{set_name}.features.csv'\n",
    "elif modality == 'ATAC':\n",
    "    quants_file = f'{quants_dir}/{set_name}.csv'\n",
    "    features_file = f'{quants_dir}/{cohort}_consensus_peaks.saf'\n",
    "elif modality == 'METH':\n",
    "    quants_file = f'{quants_dir}/{modality}.FINAL_normalized_FOUNDIN_october2020.txt.gz'\n",
    "    features_file = f'{quants_dir}/EPIC_annotation_hg38.txt'    \n",
    "covariates_file = f'{info_dir}/{cohort}_{modality}_sample_info.csv'\n",
    "\n",
    "# out files\n",
    "all_quants_file = f'{quants_dir}/{set_name}.hdf5'\n",
    "umap_covs_file = f'{info_dir}/{set_name}.umap.covs.csv'\n",
    "scaled_file = f'{quants_dir}/{set_name}.scaled.hdf5'\n",
    "adj_quants_file = f'{quants_dir}/{set_name}.scaled.adj.hdf5'\n",
    "\n",
    "# constants\n",
    "if modality == 'METH':\n",
    "    max_missing_rate = 0.75\n",
    "else:\n",
    "    max_missing_rate = 0.25\n",
    "min_ppscore = 0.05\n",
    "min_pearson = 0.22\n",
    "DEBUG = False\n",
    "low_var_quartile = '75%'\n",
    "dpi_value = 50\n",
    "\n",
    "other_id_columns = ['sampleid', 'cdi', 'PPMI_ID', 'DZNE_Barcode', 'DZNE_ID', \n",
    "                    'participant_id', 'wgsid', 'PATNO', 'Barcode_LNG', \n",
    "                    'Barcode_DZNE', 'Alternate MRN', 'IID', 'FID']\n",
    "exclude_addl_info_cols = ['data_split', 'ENSG00000188906.15', 'ENSG00000131979.18',\n",
    "                          'ENSG00000129003.17', 'ENSG00000069329.17', \n",
    "                          'ENSG00000177628.15', 'ENSG00000158828.7',\n",
    "                          'ENSG00000145335.15', 'ENSG00000164535.14', \n",
    "                          'ENSG00000165092.12', 'ENSG00000147133.15',\n",
    "                          'ENSG00000155961.4']\n",
    "# to match geno's use PPMI3966 Batch3\n",
    "replace_id_dict = {'PPMI3966B3': 'PPMI3966'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the quantified features matrix and save as hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_csv(quants_file, index_col=0)\n",
    "print(f'shape of input matrix {quants_df.shape}')\n",
    "# now save the quant matrix in faster file type\n",
    "nuf.write_df_to_hdf(quants_df, all_quants_file)\n",
    "\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split name index to find info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts = quants_df.index.str.split('_', expand=True).to_frame()\n",
    "id_parts.columns = ['assay', 'sampleid', 'day']\n",
    "# id_parts['fullassayid'] = quant_df.index\n",
    "id_parts['assayid'] = id_parts['assay'] + '_' + id_parts['sampleid'] + '_' + id_parts['day']\n",
    "print(id_parts.shape)\n",
    "if DEBUG:\n",
    "    display(id_parts.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get counts by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = id_parts['day'].value_counts()\n",
    "display(days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = read_csv(covariates_file, index_col=0)\n",
    "# drop any duplicated indices\n",
    "print(covs_df.shape)\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(covs_df.shape)\n",
    "if DEBUG:\n",
    "    display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(quants_df.index) - set(covs_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(id_parts['sampleid']) - set(covs_df['sampleid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for further analysis remove the ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covs_df.shape)\n",
    "cols_to_keep = set(covs_df.columns) - set(other_id_columns) - set(exclude_addl_info_cols)\n",
    "covs_df = covs_df[cols_to_keep]\n",
    "print(covs_df.shape)\n",
    "# display(covs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load feature annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == 'PDUI':\n",
    "    features_df = read_csv(features_file)\n",
    "    features_df.rename(columns={'Loci': 'feature'}, inplace=True)\n",
    "elif modality == 'METH':\n",
    "    features_df = read_csv(features_file, sep='\\t', header=None)\n",
    "    features_df.columns = ['Chr', 'start', 'end', 'feature']\n",
    "elif modality == 'ATAC':\n",
    "    features_df = read_csv(features_file, sep='\\t')\n",
    "    features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']    \n",
    "print(features_df.shape)\n",
    "if DEBUG:\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the quantified features matrix split by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the saves in parallel    \n",
    "with concurrent.futures.ThreadPoolExecutor() as tpe:\n",
    "    for day in days.index:\n",
    "        day_df = id_parts.loc[id_parts['day'] == day]\n",
    "        this_quant_df = quants_df[quants_df.index.isin(day_df['assayid'])]\n",
    "        print(f'{cohort} {day} {this_quant_df.shape}')\n",
    "        cohort_quant_filename = f'{quants_dir}/{cohort}_{day}_{modality}.hdf5'\n",
    "        tpe.submit(nuf.write_df_to_hdf, this_quant_df, cohort_quant_filename)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find IDs for features on sex chromosomes, for dropping later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_chr_feature_ids = features_df.loc[features_df.chrom\n",
    "                                      .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "print(len(sex_chr_feature_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373â€“84.\n",
    "\n",
    "if modality == 'ATAC':\n",
    "    sex_specific_features = ['chrX_73852329_73852963', 'chrY_2841364_2842239', \n",
    "                             'chrY_19744015_19745452', 'chrY_13478234_13480597', \n",
    "                             'chrY_12904296_12906267', 'chrY_12661424_12663659']\n",
    "elif modality == 'METH':\n",
    "    sex_specific_features = features_df.loc[features_df['Chr']\n",
    "                                          .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "elif modality == 'PDUI':\n",
    "    sex_genes = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "    sex_features = features_df.loc[features_df.Gene.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()\n",
    "else:\n",
    "    sex_specific_features = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "sex_features_present = list(set(sex_specific_features) & set(quants_df.columns))\n",
    "print(f'found {len(sex_features_present)} sex features: \\n{sex_features_present}')\n",
    "quants_sex_df = quants_df[sex_features_present].copy()\n",
    "print(f'sex features matrix shape {quants_sex_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sex_umap_df = nuf.generate_umap_covs_df(quants_sex_df, covs_df)\n",
    "nuf.plot_umap_clusters(sex_umap_df, hue_cov='sex', style_cov='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate, plot detection rates and subset well detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, max_missing_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize the dataset using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_scaled_df = nuf.scale_dataframe(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check transformation for random feature\n",
    "nuf.plot_trnsfrm_effect_example(quants_df, traits_scaled_df,\n",
    "                                bf_label=modality, \n",
    "                                af_label='quantile transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled, well detected data for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.write_df_to_hdf(traits_scaled_df, scaled_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate covariates from variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at variance in data, assuming mostly driven by d0 -> d25, ie IPSc -> differentiating neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude low variance features from covariate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_var_df = nuf.exclude_low_var_features(traits_scaled_df, \n",
    "                                             quartile_to_drop=low_var_quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_features = set(quants_var_df.columns) - (set(sex_specific_features))\n",
    "print(len(variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### not going to use PCs but take a look at PCA anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_df = nuf.generate_pca(quants_var_df[variance_features], plot_variance=True)\n",
    "print(pcs_df.shape)\n",
    "if DEBUG:\n",
    "    display(pcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pcs_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = ['PC_0', 'PC_1', 'PC_2']\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pca_pair(pcs_df, 'PC_0', 'PC_1', hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate unknown covariates and see if know covariates are source of variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = nuf.generate_umap_covs_df(quants_var_df[variance_features], covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = nuf.pps_predict_targets(umap_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "if len(covs_to_check) > 0:\n",
    "    umap_dums_covs_df = nuf.dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                          set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df)\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot umap of with known covariates of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do quick anova by day to identify features changed with cell differentiation \n",
    "\n",
    "this is since we know differention should be largest source of variation, so figure out which features to exclude to get around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split samples by group (day)\n",
    "feats_by_day = {}\n",
    "for day in days.index:\n",
    "    day_df = id_parts.loc[id_parts['day'] == day]\n",
    "    this_quant_df = traits_scaled_df[traits_scaled_df.index.isin(day_df['assayid'])]\n",
    "    feats_by_day[day] = this_quant_df\n",
    "    print(f'{cohort} {day} {this_quant_df.shape}')\n",
    "\n",
    "# calculate one-way ANOVA for the groups\n",
    "if modality == 'METH':\n",
    "    fvalues, pvalues = f_oneway(feats_by_day.get('da0'),  \n",
    "                                      feats_by_day.get('da65'))    \n",
    "else:\n",
    "    fvalues, pvalues = f_oneway(feats_by_day.get('da0'), \n",
    "                                      feats_by_day.get('da25'), \n",
    "                                      feats_by_day.get('da65'))\n",
    "\n",
    "# make df from results\n",
    "anova_results_df = DataFrame(data={'fvalues': fvalues, 'pvalues': pvalues}, \n",
    "                                index=traits_scaled_df.columns)\n",
    "# apply a B&H FDR to pvalues\n",
    "anova_results_df['bh_fdr'] = smm.fdrcorrection(anova_results_df.pvalues.fillna(1))[1]\n",
    "\n",
    "print(anova_results_df.shape)\n",
    "if DEBUG:\n",
    "    display(anova_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results_df.loc[anova_results_df['bh_fdr'] < 0.05].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### determine final set of features to use for variance detection\n",
    "exluding bottom 25% variance features, sex features, tissue elevated features, and cell differentiation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_change_features = anova_results_df.loc[anova_results_df['bh_fdr'] > 0.05].index.values\n",
    "print(len(no_change_features))\n",
    "\n",
    "no_change_variance_features = (set(no_change_features) & set(quants_var_df.columns)) - set(sex_chr_feature_ids)\n",
    "print(len(no_change_variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate unknown covariates from final set of features for variance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check PCAs again, still not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs_df = nuf.generate_pca(quants_var_df[no_change_variance_features], plot_variance=True)\n",
    "print(pcs_df.shape)\n",
    "if DEBUG:\n",
    "    display(pcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pcs_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = ['PC_0', 'PC_1', 'PC_2']\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pca_pair(pcs_df, 'PC_0', 'PC_1', hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = nuf.generate_umap_covs_df(quants_var_df[no_change_variance_features], covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = nuf.pps_predict_targets(umap_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "if len(covs_to_check) > 0:\n",
    "    umap_dums_covs_df = nuf.dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                          set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df)\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot umap of with known covariates of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='Batch', size_cov='DopaminergicNeurons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep created covars and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the covariates\n",
    "umap_covs_df = nuf.scale_dataframe(umap_df[covs_target_list])\n",
    "# now save the covariates\n",
    "umap_covs_df.to_csv(umap_covs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust the scaled data by the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see in df's have same indices\n",
    "if not traits_scaled_df.index.equals(umap_covs_df.index):\n",
    "    print('indices are not equal re-index')\n",
    "    umap_covs_df.reindex(traits_scaled_df.index)\n",
    "    \n",
    "traits_scaled_df.index.equals(umap_covs_df.index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "residuals_df, cov_scores_df = nuf.covariate_residuals(traits_scaled_df, umap_covs_df)\n",
    "\n",
    "#take a peek at the data\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)\n",
    "\n",
    "# print(cov_scores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the covariates model scores\n",
    "print(cov_scores_df.describe())\n",
    "# look at the distribution of covariate model scores, \n",
    "# ie get a sense any feature driven by covariates\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': dpi_value}):\n",
    "    plt.style.use('seaborn-bright')\n",
    "    distplot(cov_scores_df['score'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove any features that had more than 75% score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = cov_scores_df[cov_scores_df.score > 0.75].index.values\n",
    "keep_features = list(set(residuals_df.columns) - set(drop_features))\n",
    "residuals_df = residuals_df[keep_features]\n",
    "cov_scores_df = cov_scores_df.loc[cov_scores_df.index.isin(keep_features)]\n",
    "print(len(drop_features))\n",
    "print(len(keep_features))\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "residuals_df.to_hdf(adj_quants_file, key='quants', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at the scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find feature with largest score\n",
    "large_adj_trait = cov_scores_df.loc[cov_scores_df['score'] == max(cov_scores_df['score'])]\n",
    "print(large_adj_trait)\n",
    "large_adj_traid_id = large_adj_trait.index.values[0]\n",
    "\n",
    "# spot check same feature with largest adjustment effect\n",
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df, large_adj_traid_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the post scaled and covariate adjusted umap variables correlated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = nuf.generate_umap_covs_df(residuals_df, covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = nuf.pps_predict_targets(umap_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "if len(covs_to_check) > 0:\n",
    "    umap_dums_covs_df = nuf.dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                          set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df)\n",
    "    nuf.plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_umap_clusters(umap_df, hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
