{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to prep FOUNDIN-PD modalities for analyses\n",
    "will output a scaled and covariate adjusted file for full dataset; ie across days\n",
    "will also output unprepped data just split by differentiation day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, read_pickle, DataFrame\n",
    "from dask.dataframe import read_csv as dd_read_csv\n",
    "import nb_util_funcs as nuf\n",
    "# from numpy import cumsum\n",
    "import concurrent.futures\n",
    "from random import sample\n",
    "from seaborn import distplot\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.multitest as smm\n",
    "from scipy.stats import f_oneway\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebooks variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "modality = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort = 'foundin'\n",
    "set_name = f'{cohort}_daALL_{modality}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/labshare/raph/datasets/foundin_qtl'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "public_dir = f'{wrk_dir}/public'\n",
    "\n",
    "# in files\n",
    "quants_file = f'{quants_dir}/{set_name}.csv'\n",
    "if modality == 'ATAC':\n",
    "    features_file = f'{quants_dir}/{cohort}_consensus_peaks.saf'\n",
    "elif modality == 'PDUI':\n",
    "    features_file = f'{quants_dir}/{set_name}.features.csv'\n",
    "elif modality == 'METH':\n",
    "    features_file = f'{quants_dir}/EPIC_annotation_hg38.txt'    \n",
    "elif modality == 'RNAB':\n",
    "    features_file = f'{public_dir}/gencode_v29.lncipedia_v5_2_hc.annotation.pkl'\n",
    "elif modality == 'CIRC':\n",
    "    features_file = f'{quants_dir}/circRNA_genomicRegionList.tsv'    \n",
    "elif modality == 'RNAS':\n",
    "    features_file = f'{quants_dir}/{cohort}_{modality}_features.csv'    \n",
    "covariates_file = f'{info_dir}/{cohort}_{modality}_sample_info.csv'\n",
    "\n",
    "# out files\n",
    "all_quants_file = f'{quants_dir}/{set_name}.hdf5'\n",
    "var_covs_file = f'{info_dir}/{set_name}.variance.covs.csv'\n",
    "scaled_file = f'{quants_dir}/{set_name}.scaled.hdf5'\n",
    "adj_quants_file = f'{quants_dir}/{set_name}.scaled.adj.hdf5'\n",
    "\n",
    "# constants\n",
    "if modality == 'METH' or modality == 'ATAC':\n",
    "    max_missing_rate = 0.75\n",
    "else:\n",
    "    max_missing_rate = 0.25\n",
    "min_ppscore = 0.05\n",
    "min_pearson = 0.22\n",
    "DEBUG = False\n",
    "low_var_quartile = '25%'\n",
    "dpi_value = 50\n",
    "\n",
    "other_id_columns = ['sampleid', 'cdi', 'PPMI_ID', 'DZNE_Barcode', 'DZNE_ID', \n",
    "                    'participant_id', 'wgsid', 'PATNO', 'Barcode_LNG', \n",
    "                    'Barcode_DZNE', 'Alternate MRN', 'IID', 'FID']\n",
    "exclude_addl_info_cols = ['data_split', 'ENSG00000188906.15', 'ENSG00000131979.18',\n",
    "                          'ENSG00000129003.17', 'ENSG00000069329.17', \n",
    "                          'ENSG00000177628.15', 'ENSG00000158828.7',\n",
    "                          'ENSG00000145335.15', 'ENSG00000164535.14', \n",
    "                          'ENSG00000165092.12', 'ENSG00000147133.15',\n",
    "                          'ENSG00000155961.4']\n",
    "# to match geno's use PPMI3966 Batch3\n",
    "replace_id_dict = {'PPMI3966B3': 'PPMI3966'}\n",
    "\n",
    "if DEBUG:\n",
    "    print(f'quants_file = {quants_file}')\n",
    "    print(f'covariates_file = {covariates_file}')\n",
    "    print(f'features_file = {features_file}')\n",
    "    print(f'all_quants_file = {all_quants_file}')\n",
    "    print(f'var_covs_file = {var_covs_file}')\n",
    "    print(f'scaled_file = {scaled_file}')\n",
    "    print(f'adj_quants_file = {adj_quants_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the quantified features matrix and save as hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_csv(quants_file, index_col=0)\n",
    "print(f'shape of input matrix {quants_df.shape}')\n",
    "# now save the quant matrix in faster file type\n",
    "nuf.write_df_to_hdf(quants_df, all_quants_file)\n",
    "\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split name index to find info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts = quants_df.index.str.split('_', expand=True).to_frame()\n",
    "id_parts.columns = ['assay', 'sampleid', 'day']\n",
    "# id_parts['fullassayid'] = quant_df.index\n",
    "id_parts['assayid'] = id_parts['assay'] + '_' + id_parts['sampleid'] + '_' + id_parts['day']\n",
    "print(id_parts.shape)\n",
    "if DEBUG:\n",
    "    display(id_parts.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get counts by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = id_parts['day'].value_counts()\n",
    "display(days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = read_csv(covariates_file, index_col=0)\n",
    "# drop any duplicated indices\n",
    "print(covs_df.shape)\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(covs_df.shape)\n",
    "if DEBUG:\n",
    "    display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(quants_df.index) - set(covs_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(id_parts['sampleid']) - set(covs_df['sampleid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for further analysis remove the ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covs_df.shape)\n",
    "cols_to_keep = list(set(covs_df.columns) - set(other_id_columns) - set(exclude_addl_info_cols))\n",
    "covs_df = covs_df[cols_to_keep]\n",
    "print(covs_df.shape)\n",
    "# display(covs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load feature annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if modality == 'ATAC':\n",
    "    features_df = read_csv(features_file, sep='\\t')\n",
    "    features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']\n",
    "elif modality == 'METH':\n",
    "    features_df = read_csv(features_file, sep='\\t', header=None)\n",
    "    features_df.columns = ['chrom', 'start', 'end', 'feature']\n",
    "elif modality == 'PDUI':\n",
    "    features_df = read_csv(features_file)\n",
    "    features_df = features_df.rename(columns={'Loci': 'feature'})\n",
    "elif modality == 'CIRC':\n",
    "    features_df = read_csv(features_file, sep='\\t')\n",
    "    features_df = features_df.rename(columns={'circRNA_ID': 'feature', \n",
    "                                              'chr': 'chrom', \n",
    "                                              'circRNA_start': 'start', \n",
    "                                              'circRNA_end': 'end'})\n",
    "elif modality == 'RNAB':\n",
    "    features_df = read_pickle(features_file)\n",
    "    # features_df.columns = ['feature', 'chrom', 'start', 'end', 'strand']\n",
    "    # drop the ont and tag columns\n",
    "    discard_cols = features_df.columns[(features_df.columns.str.startswith('ont')) |\n",
    "                                       (features_df.columns.str.startswith('tag')) | \n",
    "                                       (features_df.columns.str.startswith('havana_')) |                                       \n",
    "                                       (features_df.columns.str.startswith('gene_alias')) | \n",
    "                                       (features_df.columns.str.startswith('transcript_alias'))]\n",
    "    features_df = features_df.drop(columns=discard_cols)\n",
    "    # subset to just 'gene' features\n",
    "    features_df = features_df.loc[features_df.feature == 'gene']\n",
    "    # now drop existing feature col so we can use that name\n",
    "    features_df = features_df.drop(columns=['feature'])\n",
    "    features_df = features_df.rename(columns={'seqname': 'chrom', 'gene_id': 'feature'})\n",
    "elif modality == 'RNAS':\n",
    "    features_df = read_csv(features_file)\n",
    "    \n",
    "print(features_df.shape)\n",
    "if DEBUG:\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the quantified features matrix split by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the saves in parallel    \n",
    "with concurrent.futures.ThreadPoolExecutor() as tpe:\n",
    "    for day in days.index:\n",
    "        day_df = id_parts.loc[id_parts['day'] == day]\n",
    "        this_quant_df = quants_df[quants_df.index.isin(day_df['assayid'])]\n",
    "        print(f'{cohort} {day} {this_quant_df.shape}')\n",
    "        cohort_quant_filename = f'{quants_dir}/{cohort}_{day}_{modality}.hdf5'\n",
    "        tpe.submit(nuf.write_df_to_hdf, this_quant_df, cohort_quant_filename)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find IDs for features on sex chromosomes, for dropping later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_chr_feature_ids = features_df.loc[features_df.chrom\n",
    "                                      .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "print(len(sex_chr_feature_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373â€“84.\n",
    "sex_genes = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "\n",
    "if modality == 'ATAC':\n",
    "    sex_specific_features = ['chrX_73852329_73852963', 'chrY_2841364_2842239', \n",
    "                             'chrY_19744015_19745452', 'chrY_13478234_13480597', \n",
    "                             'chrY_12904296_12906267', 'chrY_12661424_12663659']\n",
    "elif modality == 'METH':\n",
    "    sex_specific_features = features_df.loc[features_df['chrom']\n",
    "                                            .isin(['chrX', 'chrY'])]['feature'].unique()\n",
    "elif modality == 'PDUI':\n",
    "    sex_features = features_df.loc[features_df.Gene.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()\n",
    "elif modality == 'RNAB':\n",
    "    sex_features = features_df.loc[features_df.gene_name.isin(sex_genes)]\n",
    "    sex_specific_features = sex_features.feature.to_list()\n",
    "elif modality == 'CIRC':\n",
    "    sex_specific_features = ['chrX:73852031|73852204', 'chrX:73826115|73837503', \n",
    "                             'chrY:2845670|2854771', 'chrY:2865189|2866886', \n",
    "                             'chrY:2854744|2865182', 'chrY:2890914|2891101', \n",
    "                             'chrY:2847677|2847984', 'chrY:2854733|2865176', \n",
    "                             'chrY:19739528|19741857', 'chrY:13251002|13369349', \n",
    "                             'chrY:13323555|13378010', 'chrY:13369256|13400051', \n",
    "                             'chrY:13393859|13450820', 'chrY:13410993|13470229', \n",
    "                             'chrY:12909360|12913062', 'chrY:12912963|12914649', \n",
    "                             'chrY:12912963|12914982', 'chrY:12909363|12913062', \n",
    "                             'chrY:12909360|12914649', 'chrY:12707760|12709543', \n",
    "                             'chrY:12709279|12709543', 'chrY:12716791|12841133', \n",
    "                             'chrY:12735612|12739629', 'chrY:12738157|12758642']\n",
    "elif modality == 'RNAS':\n",
    "    sex_specific_features = list(sex_chr_feature_ids)    \n",
    "else:\n",
    "    sex_specific_features = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "sex_features_present = list(set(sex_specific_features) & set(quants_df.columns))\n",
    "print(f'found {len(sex_features_present)} sex features: \\n{sex_features_present}')\n",
    "quants_sex_df = quants_df[sex_features_present].copy()\n",
    "print(f'sex features matrix shape {quants_sex_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_,sex_pca_df,_,_ = nuf.generate_selected_model(2, quants_sex_df, 'PCA')\n",
    "print(f'shape of sex_pca_df is {sex_pca_df.shape}')\n",
    "nuf.plot_pair(sex_pca_df.merge(covs_df, how='left', \n",
    "                               left_index=True, right_index=True),\n",
    "              'PCA_0', 'PCA_1', hue_cov='sex', style_cov='Batch')\n",
    "if DEBUG:\n",
    "    display(sex_pca_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize the sexomes features in 2D with MDE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuf.show_2d_embed(quants_sex_df, covs_df, type='MDE', hue='sex', style='day')\n",
    "nuf.show_2d_embed(quants_sex_df, covs_df, type='UMAP', hue='sex', style='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate, plot detection rates and subset well detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, max_missing_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize the dataset using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_scaled_df = nuf.scale_dataframe(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check transformation for random feature\n",
    "nuf.plot_trnsfrm_effect_example(quants_df, traits_scaled_df,\n",
    "                                bf_label=modality, \n",
    "                                af_label='quantile transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled, well detected data for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.write_df_to_hdf(traits_scaled_df, scaled_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate covariates from variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at variance in data, assuming mostly driven by d0 -> d65, ie IPSc -> differentiating neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude low variance features from covariate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_var_df = nuf.exclude_low_var_features(traits_scaled_df, \n",
    "                                             quartile_to_drop=low_var_quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_features = list(set(quants_var_df.columns) - set(sex_chr_feature_ids))\n",
    "print(len(variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use PCA to model unknown covariates, ie global variance covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model PCA accuracy with different number of component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(quants_var_df[variance_features].shape[0], quants_var_df[variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, quants_var_df[variance_features], 'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, quants_var_df[variance_features], 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "nuf.plot_pair(pca_df.merge(covs_df, how='left', left_index=True, right_index=True), \n",
    "              'PCA_0', 'PCA_1', hue_cov='day', style_cov='Batch')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='MDE', hue='day', style='Batch')\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='UMAP', hue='day', style='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do quick anova by day to identify features that may be changed with cell differentiation \n",
    "\n",
    "this is since we know differention should be largest source of variation, so figure out which features to exclude to get around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split samples by group (day)\n",
    "feats_by_day = {}\n",
    "for day in days.index:\n",
    "    day_df = id_parts.loc[id_parts['day'] == day]\n",
    "    this_quant_df = traits_scaled_df[traits_scaled_df.index.isin(day_df['assayid'])]\n",
    "    feats_by_day[day] = this_quant_df\n",
    "    print(f'{cohort} {day} {this_quant_df.shape}')\n",
    "\n",
    "# calculate one-way ANOVA for the groups\n",
    "if modality == 'METH':\n",
    "    fvalues, pvalues = f_oneway(feats_by_day.get('da0'),  \n",
    "                                      feats_by_day.get('da65'))    \n",
    "else:\n",
    "    fvalues, pvalues = f_oneway(feats_by_day.get('da0'), \n",
    "                                      feats_by_day.get('da25'), \n",
    "                                      feats_by_day.get('da65'))\n",
    "\n",
    "# make df from results\n",
    "anova_results_df = DataFrame(data={'fvalues': fvalues, 'pvalues': pvalues}, \n",
    "                                index=traits_scaled_df.columns)\n",
    "# apply a B&H FDR to pvalues\n",
    "anova_results_df['bh_fdr'] = smm.fdrcorrection(anova_results_df.pvalues.fillna(1))[1]\n",
    "\n",
    "print(anova_results_df.shape)\n",
    "if DEBUG:\n",
    "    display(anova_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results_df.loc[anova_results_df['bh_fdr'] < 0.05].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### determine final set of features to use for variance detection\n",
    "exluding bottom 25% variance features, sex features, tissue elevated features, and cell differentiation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_change_features = anova_results_df.loc[anova_results_df['bh_fdr'] > 0.05].index.values\n",
    "print(len(no_change_features))\n",
    "\n",
    "no_change_variance_features = list((set(no_change_features) & set(quants_var_df.columns)) - set(sex_chr_feature_ids))\n",
    "print(len(no_change_variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remodel with new variance feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(quants_var_df[no_change_variance_features].shape[0], \n",
    "                    quants_var_df[no_change_variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, \n",
    "                                                            quants_var_df[no_change_variance_features], \n",
    "                                                            'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, quants_var_df[no_change_variance_features], 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pca_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "if DEBUG:\n",
    "    display(pcs_df.head())\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = pca_df.columns.to_list()\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(pcs_df, 'PCA_0', 'PCA_1', hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(covs_to_check) > 0:\n",
    "    pcs_dums_covs_df = nuf.dummy_covs_as_needed(pcs_df[list(set(covs_to_check) | set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(pcs_dums_covs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='MDE', hue='day', style='Batch')\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='UMAP', hue='day', style='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save created variance covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the covariates\n",
    "var_covs_df = nuf.scale_dataframe(pca_df, with_qt=False)\n",
    "# now save the covariates\n",
    "var_covs_df.to_csv(var_covs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust the scaled data by the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see in df's have same indices\n",
    "if not traits_scaled_df.index.equals(var_covs_df.index):\n",
    "    print('indices are not equal re-index')\n",
    "    shared_indices = traits_scaled_df.index.intersection(var_covs_df.index)\n",
    "    traits_scaled_df = traits_scaled_df.loc[shared_indices,]\n",
    "    var_covs_df = var_covs_df.loc[shared_indices,]    \n",
    "    \n",
    "traits_scaled_df.index.equals(var_covs_df.index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "residuals_df, cov_scores_df = nuf.covariate_residuals(traits_scaled_df, var_covs_df)\n",
    "\n",
    "#take a peek at the data\n",
    "print(f'residuals shape {residuals_df.shape}')\n",
    "print(f'scores shape {cov_scores_df.shape}')\n",
    "if DEBUG:\n",
    "    display(cov_scores_df.head())\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the covariates model scores\n",
    "print(cov_scores_df.describe())\n",
    "# look at the distribution of covariate model scores, \n",
    "# ie get a sense any feature driven by covariates\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': dpi_value}):\n",
    "    plt.style.use('seaborn-bright')\n",
    "    distplot(cov_scores_df['score'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how many features have more than 75% score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = cov_scores_df[cov_scores_df.score > 0.75].index.values\n",
    "keep_features = list(set(residuals_df.columns) - set(drop_features))\n",
    "print(len(drop_features))\n",
    "print(len(keep_features))\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "nuf.write_df_to_hdf(residuals_df, adj_quants_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at the scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find feature with largest score\n",
    "large_adj_trait = cov_scores_df.loc[cov_scores_df['score'] == max(cov_scores_df['score'])]\n",
    "print(large_adj_trait)\n",
    "large_adj_traid_id = large_adj_trait.index.values[0]\n",
    "\n",
    "# spot check same feature with largest adjustment effect\n",
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df, large_adj_traid_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the post scaled and covariate adjusted latent variables correlated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(residuals_df[no_change_variance_features].shape[0], \n",
    "                    residuals_df[no_change_variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, \n",
    "                                                            residuals_df[no_change_variance_features], \n",
    "                                                            'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "# num_comp = max(knee_rmse, knee_r2)\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, \n",
    "                                                 residuals_df[no_change_variance_features], \n",
    "                                                 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pca_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = pca_df.columns.to_list()\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(pcs_df, 'PCA_0', 'PCA_1', hue_cov='day', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(covs_to_check) > 0:\n",
    "    dums_covs_df = nuf.dummy_covs_as_needed(pcs_df[list(set(covs_to_check) | \n",
    "                                                        set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(dums_covs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='MDE', hue='day', style='Batch')\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='UMAP', hue='day', style='Batch')\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='MDE', hue='day', size='DopaminergicNeurons')\n",
    "nuf.show_2d_embed(pca_df, covs_df, type='UMAP', hue='day', size='DopaminergicNeurons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
