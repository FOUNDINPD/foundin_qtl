{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook that pulls together known subject and sample covariates cleans up as neccessary and writes to single file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter variables\n",
    "cohort = 'foundin'\n",
    "modality = 'ATAC'\n",
    "\n",
    "# directories \n",
    "wrk_dir = f'/home/jupyter/{cohort}/eqtl'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "\n",
    "# input files\n",
    "subject_info_file = f'{info_dir}/amppd_demographicsPlus_2019_v1release_1015.csv'\n",
    "cell_info_file = f'{info_dir}/cell_metadata.csv'\n",
    "genos_pca_file = f'{info_dir}/foundin.freeze9.pca.eigenvec'\n",
    "cell_fracs_file = f'{info_dir}/rnab_cell_fracs_scaden.csv'\n",
    "if modality == 'RNAB':\n",
    "    assay_metrics_file = f'{info_dir}/foundin_rnab_seqqc_metrics.txt'\n",
    "elif modality == 'ATAC':\n",
    "    assay_metrics_file = f'{info_dir}/foundin_atac_metrics.csv'\n",
    "elif modality == 'SCRN':\n",
    "    assay_metrics_file = f'{info_dir}/COVARIATES_BATCH.txt'    \n",
    "subj_overview_file = f'{info_dir}/Expanded_overview_of_included_PPMI_samples_overview.csv'\n",
    "subj_grs_file = f'{info_dir}/Expanded_overview_of_included_PPMI_samples_GRS.csv'\n",
    "\n",
    "# output files\n",
    "assay_covs_files = f'{info_dir}/foundin_{modality}_sample_info.csv'\n",
    "\n",
    "# constants\n",
    "max_cov_missing_rate = 0.5\n",
    "repeated_id_dict = {'PPMI3966B1': 'PPMI3966', 'PPMI3966B2': 'PPMI3966', \n",
    "                    'PPMI3966B3': 'PPMI3966', 'PPMI3966B5': 'PPMI3966'}\n",
    "\n",
    "covs_index_assay_id_to_replace = {f'{modality}_PPMI3422_0683_da65_v1': f'{modality}_PPMI3422_1260_da65_v1',\n",
    "                                  f'{modality}_PPMI3448_3236_da65_v1': f'{modality}_PPMI3448_2397_da65_v1',\n",
    "                                  f'{modality}_PPMI3451_2397_da65_v1': f'{modality}_PPMI3451_3236_da65_v1',\n",
    "                                  f'{modality}_PPMI3664_6647_da65_v1': f'{modality}_PPMI3664_2833_da65_v1',\n",
    "                                  f'{modality}_PPMI3665_7215_da65_v1': f'{modality}_PPMI3665_4484_da65_v1',\n",
    "                                  f'{modality}_PPMI3953_2833_da65_v1': f'{modality}_PPMI3953_6647_da65_v1',\n",
    "                                  f'{modality}_PPMI4101_4484_da65_v2': f'{modality}_PPMI4101_7215_da65_v2',\n",
    "                                  f'{modality}_PPMI4106_2056_da65_v1': f'{modality}_PPMI4106_0494_da65_v1',\n",
    "                                  f'{modality}_PPMI54991_1260_da65_v1': f'{modality}_PPMI54991_0683_da65_v1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cell line info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_info = pd.read_csv(cell_info_file)\n",
    "print(cell_info.shape)\n",
    "# add 'PPMI' to patno\n",
    "cell_info['PPMI_ID'] = 'PPMI' + cell_info['PPMI_ID'].astype(str)\n",
    "# display(cell_info.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load subject info file, from AMP-PD, and merge with cell info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_info = pd.read_csv(subject_info_file)\n",
    "subj_info['wgsid'] = subj_info['participant_id']\n",
    "subj_info['participant_id'] = subj_info['participant_id'].str.replace('PP-', 'PPMI')\n",
    "print(subj_info.shape)\n",
    "# display(subj_info.head())\n",
    "\n",
    "# now merge cell and subject info\n",
    "info_df = pd.merge(cell_info, subj_info, how='left', left_on='PPMI_ID', right_on='participant_id')\n",
    "print(info_df.shape)\n",
    "# display(info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the FOUNDIN subject overiew files and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df = pd.read_csv(subj_overview_file)\n",
    "overview_df['PPMI_ID'] = 'PPMI' + overview_df['PATNO'].astype(str)\n",
    "print(overview_df.shape)\n",
    "# display(overview_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_df = pd.read_csv(subj_grs_file)\n",
    "grs_df['PPMI_ID'] = grs_df['IID'].str.replace('PPMISI', 'PPMI')\n",
    "print(grs_df.shape)\n",
    "# display(grs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these originated from same file, think they have duplicated columns\n",
    "print(set(overview_df.columns) & set(grs_df.columns))\n",
    "display(overview_df.info())\n",
    "display(grs_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['RECRUITMENT_CAT', 'exclude', 'DESCRP_CAT', 'IID', 'IID', \n",
    "                'PHENO', 'NOTE']\n",
    "grs_df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# couple of the categoricals look like they have decent amount of missing\n",
    "check_these_columns = ['DESCRP_CAT', 'mutation', 'Relatives', 'exclude']\n",
    "\n",
    "for this_col in check_these_columns:\n",
    "    print(this_col)\n",
    "    print(overview_df[this_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so those missing can be filled with None category instead of missing\n",
    "for this_col in check_these_columns:\n",
    "    overview_df[this_col].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge overview and grs\n",
    "overview_df = overview_df.merge(grs_df, how='left', on='PPMI_ID')\n",
    "print(overview_df.shape)\n",
    "# display(overview_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with large info\n",
    "info_df = info_df.merge(overview_df, how='left', on='PPMI_ID')\n",
    "print(info_df.shape)\n",
    "# display(info_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and merge in the genetics PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_components_df = pd.read_csv(genos_pca_file, sep='\\s+', index_col=1)\n",
    "genetic_components_df.drop(columns=['#FID'], inplace=True)\n",
    "print(genetic_components_df.shape)\n",
    "\n",
    "# merge genetics PCs with other info\n",
    "info_df = info_df.merge(genetic_components_df, how='left', left_on='wgsid', right_index=True)\n",
    "print(info_df.shape)\n",
    "# display(info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the sample assays metrics info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sample QC info\n",
    "if modality == 'SCRN':\n",
    "    metrics_info = pd.read_csv(assay_metrics_file, sep='\\t', index_col=0).transpose()\n",
    "    cols_to_keep = ['Estimated.Number.of.Cells', 'Mean.Reads.per.Cell', \n",
    "                    'Total.Genes.Detected', 'Median.UMI.Counts.per.Cell']\n",
    "    metrics_info = metrics_info[cols_to_keep]    \n",
    "else:\n",
    "    metrics_info = pd.read_csv(assay_metrics_file, sep='\\t', index_col=0)\n",
    "print(metrics_info.shape)\n",
    "# display(metrics_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename assayID that may be mismatched in metrics file\n",
    "metrics_info.rename(index=covs_index_assay_id_to_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split sample name index into constituent bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['assay', 'sampleid', 'cdi', 'day', 'version']\n",
    "id_parts = metrics_info.index.str.split('_', expand=True).to_frame(index=False, name=col_names)\n",
    "id_parts['assayid'] = metrics_info.index\n",
    "print(id_parts.shape)\n",
    "# display(id_parts.sample(5))\n",
    "# fix sampleid for repeated sample \n",
    "id_parts['sampleid'].replace(repeated_id_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get counts by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts['day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge the split assay IDs bits onto the other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = id_parts.merge(info_df, how='left', left_on='sampleid', right_on='PPMI_ID')\n",
    "info_df.drop_duplicates(subset=['assayid'], inplace=True)\n",
    "info_df.set_index('assayid', drop=True, inplace=True)\n",
    "print(info_df.shape)\n",
    "# display(info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now merge the assay QC/metrics with rest of info by assay's sample id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = info_df.merge(metrics_info, how='left', left_index=True, right_index=True)\n",
    "print(info_df.shape)\n",
    "# display(info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the cell fractions and merge with other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfracs_df = pd.read_csv(cell_fracs_file, index_col=0)\n",
    "print(cfracs_df.shape)\n",
    "\n",
    "info_df = info_df.merge(cfracs_df, how='left', left_index=True, right_index=True)\n",
    "print(info_df.shape)\n",
    "# display(info_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the dtypes and fix as neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# display(info_df.dtypes)\n",
    "display(info_df.info())\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get rid of the columns that have single values or a lot missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "for this_col in info_df.columns:\n",
    "    drop_col = False\n",
    "    try:\n",
    "        percent_miss = info_df[this_col].isna().sum()/info_df.shape[0]\n",
    "        if percent_miss > max_cov_missing_rate:\n",
    "            drop_col = True\n",
    "        else:\n",
    "            total_unique = len(info_df[this_col].unique())\n",
    "            if total_unique == 1 or (total_unique == info_df.shape[0] \n",
    "                                     and info_df[this_col].dtype == 'object'):\n",
    "                drop_col = True\n",
    "    except:\n",
    "        drop_col = True\n",
    "\n",
    "    if drop_col:\n",
    "        cols_to_drop.append(this_col)\n",
    "\n",
    "        \n",
    "print(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df['ethnicity_y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix those assay metrics colnames that have preceeding spaces\n",
    "if modality == 'RNAB':\n",
    "    cols_new_names = {' Proper Pairs': 'ProperPairs', ' Assigned': 'Assigned', \n",
    "                      'M Assigned': 'MAssigned', ' Aligned': 'Aligned', \n",
    "                      'M Aligned': 'MAligned', ' Aligned.1': 'Aligned.1', \n",
    "                      'M Aligned.1': 'MAligned.1', ' Dups': 'Dups', ' GC': 'GC',\n",
    "                      'M Seqs': 'MSeqs'}\n",
    "    info_df.rename(columns=cols_new_names, inplace=True)\n",
    "elif modality == 'SCRN':\n",
    "    cols_new_names = {'Estimated.Number.of.Cells': 'EstimatedNumberofCells',\n",
    "                      'Mean.Reads.per.Cell': 'MeanReadsperCell',\n",
    "                      'Total.Genes.Detected': 'TotalGenesDetected',\n",
    "                      'Median.UMI.Counts.per.Cell': 'MedianUMICountsperCell'}    \n",
    "    info_df.rename(columns=cols_new_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if sample without WGS is still there, ie won't have genetic PCs computed\n",
    "info_df.loc[info_df['wgsid'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which samples are missing cell fractions\n",
    "if modality == 'SCRN':\n",
    "    print(info_df.loc[info_df['EstimatedNumberofCells'].isna()].shape)\n",
    "    display(info_df.loc[info_df['EstimatedNumberofCells'].isna()])\n",
    "    print(info_df.loc[info_df['EstimatedNumberofCells'].isna()].index)    \n",
    "else:\n",
    "    print(info_df.loc[info_df['DopaminergicNeurons'].isna()].shape)\n",
    "    display(info_df.loc[info_df['DopaminergicNeurons'].isna()])\n",
    "    print(info_df.loc[info_df['DopaminergicNeurons'].isna()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for specific later cell-type specific analyses combine DopaminergicNeurons and ImmatureDopaminergicNeurons into DAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality != 'SCRN':\n",
    "    info_df['DAn'] = info_df['DopaminergicNeurons'] + info_df['ImmatureDopaminergicNeurons']\n",
    "    print(info_df[['DAn', 'DopaminergicNeurons', 'ImmatureDopaminergicNeurons']].describe())\n",
    "# display(info_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if those columns look useless drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.drop(columns=cols_to_drop, inplace=True)\n",
    "print(info_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save the complete covariates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.to_csv(assay_covs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look to see how corrlated or predictive covariates are and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use Predictive Power Score to see what is associated with predict cell fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfrac_covs = []\n",
    "for cell_type in cfracs_df.columns:\n",
    "    print(cell_type)\n",
    "    # remove the other cell types\n",
    "    other_cells = set(cfracs_df.columns) - set([cell_type])\n",
    "    this_df = info_df.drop(columns=other_cells)\n",
    "    predictors_df = pps.predictors(this_df, cell_type)\n",
    "    # drop anything that has ppscore of zero\n",
    "    predictors_df = predictors_df.loc[predictors_df['ppscore'] > 0]\n",
    "    display(predictors_df)\n",
    "    cfrac_covs.extend(list(predictors_df['x'].values))\n",
    "\n",
    "print(cfrac_covs)\n",
    "\n",
    "# check other cell type related covariates for ther predictorsTH_SCRN\n",
    "temp_other_covs = ['TH_SCRN', 'MAP2_SCRN']\n",
    "for this_cov in temp_other_covs:\n",
    "    print(this_cov)\n",
    "    predictors_df = pps.predictors(info_df, this_cov)\n",
    "    # drop anything that has ppscore of zero\n",
    "    predictors_df = predictors_df.loc[predictors_df['ppscore'] > 0]\n",
    "    display(predictors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pps.matrix(info_df[list(set(cfrac_covs) | set(cfracs_df.columns))])\n",
    "matrix_df = matrix_df.loc[matrix_df['ppscore'] > 0]\n",
    "print(matrix_df.shape)\n",
    "\n",
    "matrix_df['ppscore'] = matrix_df['ppscore'].round(2)\n",
    "plot_matrix_df = matrix_df[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "print(plot_matrix_df.shape)\n",
    "display(plot_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16)) \n",
    "sns.heatmap(plot_matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.05, \n",
    "            annot=True, annot_kws={\"fontsize\":12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = info_df[list(set(cfrac_covs) | set(cfracs_df.columns))]\n",
    "cats_df = temp_df.select_dtypes(include=['object'])\n",
    "print(cats_df.shape)\n",
    "dums_df = pd.get_dummies(cats_df)\n",
    "print(dums_df.shape)\n",
    "\n",
    "covs_df = temp_df.merge(dums_df, how='inner', left_index=True, right_index=True)\n",
    "print(covs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cor = covs_df.corr(method='pearson')\n",
    "cor.dropna(how='all', inplace=True)\n",
    "print(cor.shape)\n",
    "plt.figure(figsize=(16,16))        \n",
    "sns.heatmap(cor[(cor > 0.22) | (cor < -0.22)], annot=True, annot_kws={\"fontsize\":10}, \\\n",
    "            linewidths=0.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of warning can be generated related to number of members and n_splits=4\n",
    "# so temp supress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "matrix_df = pps.matrix(info_df)\n",
    "matrix_df = matrix_df.loc[matrix_df['ppscore'] > 0]\n",
    "print(matrix_df.shape)\n",
    "\n",
    "default_max_rows = pd.get_option('display.max_rows')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "display(matrix_df)\n",
    "pd.set_option('display.max_rows', default_max_rows)\n",
    "\n",
    "# restore defaults warning setting\n",
    "# warnings.filterwarnings('default')\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df['ppscore'] = matrix_df['ppscore'].round(2)\n",
    "plot_matrix_df = matrix_df[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "print(plot_matrix_df.shape)\n",
    "display(plot_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(24,20)) \n",
    "# sns.heatmap(plot_matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.05, \n",
    "#             annot=True, annot_kws={\"fontsize\":10})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats_df = info_df.select_dtypes(include=['object'])\n",
    "cats_df = info_df[['day', 'version', 'Batch', 'Culture_Media_iPSC', 'Growth_iPSC',\n",
    "                   'Spontaneous_differentiation', 'Differentiation_Start',\n",
    "                   'visit_name', 'sex', 'ethnicity_x', 'race',\n",
    "                   'education_level_years', 'diagnosis_at_baseline', \n",
    "                   'diagnosis_latest', 'case_control_other_at_baseline', \n",
    "                   'case_control_other_latest', 'study_arm', 'prodromal_category', \n",
    "                   'Recruitment', 'RECRUIT', 'DX_INIT', 'DIAG', 'RECRUITMENT_CAT', \n",
    "                   'IMAGING_CAT', 'ENROLL_CAT', 'DESCRP_CAT', 'pheno',\n",
    "                   'mutation', 'Relatives', 'GROUP']]\n",
    "print(cats_df.shape)\n",
    "dums_df = pd.get_dummies(cats_df)\n",
    "print(dums_df.shape)\n",
    "\n",
    "covs_df = info_df.merge(dums_df, how='inner', left_index=True, right_index=True)\n",
    "print(covs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cor = covs_df.corr(method='pearson')\n",
    "cor.dropna(how='all', inplace=True)\n",
    "print(cor.shape)\n",
    "plt.figure(figsize=(24,20))        \n",
    "sns.heatmap(cor[(cor > 0.22) | (cor < -0.22)], annot=True, annot_kws={\"fontsize\":10}, \\\n",
    "            linewidths=0.05)\n",
    "# sns.heatmap(cor[(cor > 0.1) | (cor < -0.1)], annot=True, annot_kws={\"fontsize\":12}, \\\n",
    "#             linewidths=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
