{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook to split FOUNDIN-PD SCRN quants by celltype\n",
    "will also output a scaled and covariate adjusted file for full dataset; ie across defined cell-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, read_pickle, DataFrame\n",
    "import nb_util_funcs as nuf\n",
    "import concurrent.futures\n",
    "from random import sample\n",
    "from seaborn import distplot\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.multitest as smm\n",
    "from scipy.stats import f_oneway\n",
    "from matplotlib.pyplot import rc_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "# for white background of figures (only for docs rendering)\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set notebooks variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort = 'foundin'\n",
    "modality = 'SCRN'\n",
    "day = 'da65'\n",
    "set_name = f'{cohort}_daALL_{modality}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = '/labshare/raph/datasets/foundin_qtl'\n",
    "quants_dir = f'{wrk_dir}/quants'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "public_dir = f'{wrk_dir}/public'\n",
    "\n",
    "# in files\n",
    "quants_local_file = f'{quants_dir}/{modality}.avgnormbroad.csv'\n",
    "features_file = f'{public_dir}/gencode_v29.lncipedia_v5_2_hc.annotation.pkl'\n",
    "covariates_file = f'{info_dir}/{cohort}_{modality}_sample_info.csv'\n",
    "\n",
    "# out files\n",
    "all_quants_file = f'{quants_dir}/{set_name}.hdf5'\n",
    "var_covs_file = f'{info_dir}/{set_name}.variance.covs.csv'\n",
    "scaled_file = f'{quants_dir}/{set_name}.scaled.hd5f'\n",
    "adj_quants_file = f'{quants_dir}/{set_name}.scaled.adj.hdf5'\n",
    "\n",
    "# variable\n",
    "max_missing_rate = 0.965\n",
    "min_ppscore = 0.05\n",
    "min_pearson = 0.22\n",
    "low_var_quartile = '25%'\n",
    "DEBUG = True\n",
    "dpi_value = 50\n",
    "other_id_columns = ['sampleid', 'cdi', 'PPMI_ID', 'DZNE_Barcode', 'DZNE_ID', \n",
    "                    'participant_id', 'wgsid', 'PATNO', 'Barcode_LNG', \n",
    "                    'Barcode_DZNE', 'Alternate MRN', 'IID', 'FID', 'fullassayid']\n",
    "cell_abbrvs = {'Immature Dopaminergic Neurons': 'iDA', \n",
    "              'Dopaminergic Neurons': 'DA', \n",
    "              'Proliferating Floor Plate Progenitors': 'PFPP', \n",
    "              'Early neuron Progenitor': 'eNP', \n",
    "              'Ependymal-like Cells': 'ElC', \n",
    "              'Late neuron Progenitor': 'lNP', \n",
    "              'Neuroepithelial-like Cells': 'NlC'}\n",
    "\n",
    "if DEBUG:\n",
    "    print(f'quants_local_file = {quants_local_file}')\n",
    "    print(f'covariates_file = {covariates_file}')\n",
    "    print(f'features_file = {features_file}')\n",
    "    print(f'all_quants_file = {all_quants_file}')\n",
    "    print(f'var_covs_file = {var_covs_file}')\n",
    "    print(f'scaled_file = {scaled_file}')\n",
    "    print(f'adj_quants_file = {adj_quants_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the quantified features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quants_df = read_csv(quants_local_file, sep='\\t')\n",
    "quants_df = quants_df.transpose()\n",
    "print(f'shape of input matrix {quants_df.shape}')\n",
    "\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split name index to find info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts = quants_df.index.str.split(':', expand=True).to_frame()\n",
    "id_parts.columns = ['assayid', 'cell_type']\n",
    "# id_parts['cell_type'] = id_parts['cell_type'].str.replace(' ','')\n",
    "id2_parts = id_parts['assayid'].str.split('_', expand=True)\n",
    "id2_parts.columns = ['assay', 'sampleid', 'cdi', 'day']\n",
    "id_parts['fullassayid'] = quants_df.index\n",
    "id_parts['assay'] = id2_parts['assay']\n",
    "id_parts['sampleid'] = id2_parts['sampleid']\n",
    "id_parts['cdi'] = id2_parts['cdi']\n",
    "id_parts['day'] = id2_parts['day']\n",
    "print(f'shape of id parts {id_parts.shape}')\n",
    "if DEBUG:\n",
    "    display(id_parts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(id_parts.loc[id_parts.sampleid.str.startswith('PPMI3966')])                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the cell type counts and day counts (should only be day 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_parts['cell_type'].value_counts())\n",
    "print(id_parts['day'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace cell-type name with abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts.cell_type.replace(cell_abbrvs, inplace=True)\n",
    "print(f'shape of id parts {id_parts.shape}')\n",
    "print(id_parts['cell_type'].value_counts())\n",
    "if DEBUG:\n",
    "    display(id_parts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now assign assay ID consistent with other modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts.assayid = f'{modality}-' + id_parts.cell_type+ '_' + id_parts.sampleid+ '_' + id_parts.day\n",
    "if DEBUG:\n",
    "    display(id_parts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(id_parts.loc[id_parts.sampleid.str.startswith('PPMI3966')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### capture the assayid to wgsid for formatting phenotypes for use with wgs genotypes later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = id_parts[['sampleid', 'assayid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(id_map.loc[id_map.sampleid.str.startswith('PPMI3966')])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(id_map.sampleid.value_counts())\n",
    "    print(id_map.assayid.value_counts())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace the quants matrix index with the corrected ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_df.index = id_parts.assayid\n",
    "quants_df.index.set_names('assayid')\n",
    "if DEBUG:\n",
    "    display(quants_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print(quants_df.index.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the quant matrix in faster file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nuf.write_df_to_hdf(quants_df, all_quants_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = read_csv(covariates_file, index_col=0)\n",
    "# drop any duplicated indices\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(id_parts['sampleid']) - set(covs_df['PPMI_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for merging known covariates with umaps will need to add cell labelled assay ids into covariates dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_parts.reset_index(inplace=True)\n",
    "id_parts.drop(columns=['level_0', 'level_1'], inplace=True)\n",
    "covs_df = covs_df.merge(id_parts, left_on='PPMI_ID', right_on='sampleid')\n",
    "covs_df.index = covs_df['assayid']\n",
    "covs_df = covs_df[~covs_df.index.duplicated(keep='first')]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    display(covs_df.sampleid.value_counts())\n",
    "    display(covs_df.assayid.value_counts())\n",
    "    display(covs_df.cell_type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load feature annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features_df = read_pickle(features_file)\n",
    "# drop the ont and tag columns\n",
    "discard_cols = features_df.columns[(features_df.columns.str.startswith('ont')) |\n",
    "                                   (features_df.columns.str.startswith('tag')) | \n",
    "                                   (features_df.columns.str.startswith('havana_')) |                                       \n",
    "                                   (features_df.columns.str.startswith('gene_alias')) | \n",
    "                                   (features_df.columns.str.startswith('transcript_alias'))]\n",
    "features_df.drop(columns=discard_cols, inplace=True)\n",
    "# subset to just 'gene' features\n",
    "features_df = features_df.loc[features_df.feature == 'gene']\n",
    "# now drop existing feature col so we can use that name\n",
    "features_df.drop(columns=['feature'], inplace=True)    \n",
    "features_df.rename(columns={'seqname': 'chrom', 'gene_id': 'feature'}, inplace=True)\n",
    "print(f'features shape {features_df.shape}')\n",
    "if DEBUG:\n",
    "    display(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### since single-cell features are typically gene names instead of geneIDs see if missing from feature annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_missing_in_annots = set(quants_df.columns) - set(features_df['gene_name'])\n",
    "if len(genes_missing_in_annots) < 20:\n",
    "    print(len(genes_missing_in_annots))\n",
    "    print(genes_missing_in_annots)\n",
    "else:\n",
    "    print(len(genes_missing_in_annots))\n",
    "    print(list(genes_missing_in_annots)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get counts by cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = id_parts.cell_type.value_counts()\n",
    "for cell_type, count in cell_types.items():\n",
    "    print(f'{cell_type} {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the quantified features matrix and info split by cell-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run the saves in parallel    \n",
    "with concurrent.futures.ThreadPoolExecutor() as tpe:\n",
    "    for cell_type in cell_types.index:\n",
    "        # get id info for samples of this cell type\n",
    "        cell_df = id_parts.loc[id_parts.cell_type == cell_type]\n",
    "        # get quantified features for samples of this cell type\n",
    "        this_quant_df = quants_df[quants_df.index.isin(cell_df.assayid)]\n",
    "        print(f'{cohort} {cell_type} quants {this_quant_df.shape}')\n",
    "        # now save these cell type quantified features\n",
    "        cohort_quant_filename = f'{quants_dir}/{cohort}_{day}_{modality}-{cell_type}.hdf5'\n",
    "        tpe.submit(nuf.write_df_to_hdf, this_quant_df, cohort_quant_filename) \n",
    "        this_covs_df = covs_df[covs_df.index.isin(cell_df.assayid)]\n",
    "        print(f'{cohort} {cell_type} info {this_covs_df.shape}')\n",
    "        cohort_covs_filename = f'{info_dir}/{cohort}_{modality}-{cell_type}_sample_info.csv'\n",
    "        this_covs_df.to_csv(cohort_covs_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for further analysis remove the ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'covariates shape {covs_df.shape}')\n",
    "cols_to_keep = list(set(covs_df.columns) - set(other_id_columns))\n",
    "covs_df = covs_df[cols_to_keep]\n",
    "print(f'covariates shape {covs_df.shape}')\n",
    "if DEBUG:\n",
    "    display(covs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find IDs for features on sex chromosomes, for dropping later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_chr_feature_ids = features_df.loc[features_df.chrom\n",
    "                                      .isin(['chrX', 'chrY'])]['gene_name'].unique()\n",
    "print(len(sex_chr_feature_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373–84.\n",
    "\n",
    "sex_specific_features = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "sex_features_present = list(set(sex_specific_features) & set(quants_df.columns))\n",
    "print(f'found {len(sex_features_present)} sex features: \\n{sex_features_present}')\n",
    "quants_sex_df = quants_df[sex_features_present].copy()\n",
    "print(f'sex features matrix shape {quants_sex_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_,sex_pca_df,_,_ = nuf.generate_selected_model(2, quants_sex_df, 'PCA')\n",
    "print(f'shape of sex_pca_df is {sex_pca_df.shape}')\n",
    "nuf.plot_pair(sex_pca_df.merge(covs_df, how='left', \n",
    "                               left_index=True, right_index=True),\n",
    "              'PCA_0', 'PCA_1', hue_cov='sex', style_cov='cell_type')\n",
    "nuf.plot_pair(sex_pca_df.merge(covs_df, how='left', \n",
    "                               left_index=True, right_index=True),\n",
    "              'PCA_0', 'PCA_1', hue_cov='sex', style_cov='Batch')\n",
    "if DEBUG:\n",
    "    display(sex_pca_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate, plot detection rates and subset well detected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = nuf.calculate_detection_rates(quants_df, modality)\n",
    "nuf.plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = nuf.bad_callrate_features(trait_miss_rates, max_missing_rate)\n",
    "quants_wd_df = nuf.subset_well_detected_features(quants_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale the full dataset using quantile transform and minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_scaled_df = nuf.scale_dataframe(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_trnsfrm_effect_example(quants_df, traits_scaled_df,\n",
    "                                bf_label=modality, \n",
    "                                af_label='quantile transformed and scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled, well detected data for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.write_df_to_hdf(traits_scaled_df, scaled_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate covariates for variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at variance in data, assuming mostly driven by cell-type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude low variance features from covariate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_var_df = nuf.exclude_low_var_features(traits_scaled_df, \n",
    "                                             quartile_to_drop=low_var_quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_features = list(set(quants_var_df.columns) - (set(sex_specific_features)))\n",
    "print(len(variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use PCA to model unknown covariates, ie global variance covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model PCA accuracy with different number of component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(quants_var_df[variance_features].shape[0], quants_var_df[variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, quants_var_df[variance_features], 'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, quants_var_df[variance_features], 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "nuf.plot_pair(pca_df.merge(covs_df, how='left', left_index=True, right_index=True), \n",
    "              'PCA_0', 'PCA_1', hue_cov='cell_type', style_cov='Batch')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embd_df = nuf.generate_2d_embed_df(pca_df, covs_df)\n",
    "print(f'embd_df shape is {embd_df.shape}')\n",
    "if DEBUG:\n",
    "    display(embd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do quick anova by day to identify features change with cell differentiation \n",
    "\n",
    "this is since we know differention should be largest source of variation, so figure out which features to exclude to get around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split samples by group (day)\n",
    "feats_by_cell = {}\n",
    "for cell_type in cell_types.index:\n",
    "    # get id info for samples of this cell type\n",
    "    cell_df = id_parts.loc[id_parts['cell_type'] == cell_type]\n",
    "    # get quantified features for samples of this cell type\n",
    "    this_quant_df = traits_scaled_df[traits_scaled_df.index.isin(cell_df['assayid'])]\n",
    "    feats_by_cell[cell_type] = this_quant_df\n",
    "    print(f'{cohort} {cell_type} {this_quant_df.shape}')\n",
    "\n",
    "# calculate one-way ANOVA for the groups\n",
    "fvalues, pvalues = f_oneway(feats_by_cell.get('iDA'), \n",
    "                            feats_by_cell.get('DA'), \n",
    "                            feats_by_cell.get('PFPP'), \n",
    "                            feats_by_cell.get('eNP'), \n",
    "                            feats_by_cell.get('ElC'), \n",
    "                            feats_by_cell.get('lNP'), \n",
    "                            feats_by_cell.get('NlC'))\n",
    "\n",
    "# make df from results\n",
    "anova_results_df = DataFrame(data={'fvalues': fvalues, 'pvalues': pvalues}, \n",
    "                                index=traits_scaled_df.columns)\n",
    "# apply a B&H FDR to pvalues\n",
    "anova_results_df['bh_fdr'] = smm.fdrcorrection(pvalues)[1]\n",
    "\n",
    "print(anova_results_df.shape)\n",
    "if DEBUG:\n",
    "    display(anova_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results_df.loc[anova_results_df['bh_fdr'] < 0.05].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### determine final set of features to use for variance detection\n",
    "exluding bottom variance features, sex features, tissue elevated features \n",
    "\n",
    "cannot use the cell difference genes from anova as that is pretty much all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_change_features = anova_results_df.loc[anova_results_df['bh_fdr'] > 0.05].index.values\n",
    "print(len(no_change_features))\n",
    "\n",
    "no_change_variance_features = list((set(no_change_features) & set(quants_var_df.columns)) - set(sex_chr_feature_ids))\n",
    "print(len(no_change_variance_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remodel with new variance feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(quants_var_df[no_change_variance_features].shape[0], \n",
    "                    quants_var_df[no_change_variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, \n",
    "                                                            quants_var_df[no_change_variance_features], \n",
    "                                                            'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, quants_var_df[no_change_variance_features], 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "nuf.plot_pair(pca_df.merge(covs_df, how='left', left_index=True, right_index=True), \n",
    "              'PCA_0', 'PCA_1', hue_cov='cell_type', style_cov='Batch')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pca_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "if DEBUG:\n",
    "    display(pcs_df.head())\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = pca_df.columns.to_list()\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(pcs_df, 'PCA_0', 'PCA_1', hue_cov='cell_type', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(covs_to_check) > 0:\n",
    "    pcs_dums_covs_df = nuf.dummy_covs_as_needed(pcs_df[list(set(covs_to_check) | set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(pcs_dums_covs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embd_df = nuf.generate_2d_embed_df(pca_df, covs_df)\n",
    "print(f'embd_df shape is {embd_df.shape}')\n",
    "if DEBUG:\n",
    "    display(embd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', size_cov='EstimatedNumberofCells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', size_cov='MeanReadsperCell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep created covars and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the covariates\n",
    "var_covs_df = nuf.scale_dataframe(pca_df, with_qt=False)\n",
    "# now save the covariates\n",
    "var_covs_df.to_csv(var_covs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adjust the scaled data by the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see in df's have same indices\n",
    "if not traits_scaled_df.index.equals(var_covs_df.index):\n",
    "    print('indices are not equal re-index')\n",
    "    shared_indices = traits_scaled_df.index.intersection(var_covs_df.index)\n",
    "    traits_scaled_df = traits_scaled_df.loc[shared_indices,]\n",
    "    var_covs_df = var_covs_df.loc[shared_indices,]    \n",
    "    \n",
    "traits_scaled_df.index.equals(var_covs_df.index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "residuals_df, cov_scores_df = nuf.covariate_residuals(traits_scaled_df, var_covs_df)\n",
    "\n",
    "#take a peek at the data\n",
    "print(f'residuals shape {residuals_df.shape}')\n",
    "print(f'scores shape {cov_scores_df.shape}')\n",
    "if DEBUG:\n",
    "    display(cov_scores_df.head())\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the covariates model scores\n",
    "print(cov_scores_df.describe())\n",
    "# look at the distribution of covariate model scores, \n",
    "# ie get a sense any feature driven by covariates\n",
    "with rc_context({'figure.figsize': (8, 8), 'figure.dpi': dpi_value}):\n",
    "    plt.style.use('seaborn-bright')\n",
    "    distplot(cov_scores_df['score'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how many features have more than 75% score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = cov_scores_df[cov_scores_df.score > 0.75].index.values\n",
    "keep_features = list(set(residuals_df.columns) - set(drop_features))\n",
    "print(len(drop_features))\n",
    "print(len(keep_features))\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "nuf.write_df_to_hdf(residuals_df, adj_quants_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at the scaled and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find feature with largest score\n",
    "large_adj_trait = cov_scores_df.loc[cov_scores_df['score'] == max(cov_scores_df['score'])]\n",
    "print(large_adj_trait)\n",
    "large_adj_traid_id = large_adj_trait.index.values[0]\n",
    "\n",
    "# spot check same feature with largest adjustment effect\n",
    "nuf.plot_trnsfrm_effect_example(traits_scaled_df, residuals_df, large_adj_traid_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the post scaled and covariate adjusted latent variables correlated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_count = int(min(residuals_df[no_change_variance_features].shape[0], \n",
    "                    residuals_df[no_change_variance_features].shape[1])/2)\n",
    "print(f'max count is {max_count}')\n",
    "\n",
    "r2_values, rmse_values = nuf.iterate_model_component_counts(max_count, \n",
    "                                                            residuals_df[no_change_variance_features], \n",
    "                                                            'PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use max curvature of accuracy to select number of components to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knee_rmse = nuf.component_from_max_curve(rmse_values, 'RMSE')\n",
    "knee_r2 = nuf.component_from_max_curve(r2_values, 'R2')\n",
    "# num_comp = max(knee_rmse, knee_r2)\n",
    "num_comp = min(knee_rmse, knee_r2)\n",
    "print(num_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate the PCA model with the selected number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mdl,pca_df,_,_ = nuf.generate_selected_model(num_comp, \n",
    "                                                 residuals_df[no_change_variance_features], \n",
    "                                                 'PCA')\n",
    "print(f'shape of pca_df is {pca_df.shape}')\n",
    "nuf.plot_pair(pca_df.merge(covs_df, how='left', left_index=True, right_index=True), \n",
    "          'PCA_0', 'PCA_1', hue_cov='cell_type', style_cov='Batch')\n",
    "print(pca_mdl.explained_variance_ratio_)\n",
    "if DEBUG:\n",
    "    display(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pcs_df = pca_df.merge(covs_df, how='left', left_index=True, right_index=True)\n",
    "# since just checking the PCs and not using just run ppscore on 1st three\n",
    "covs_target_list = pca_df.columns.to_list()\n",
    "covs_to_check = nuf.pps_predict_targets(pcs_df, covs_target_list)\n",
    "nuf.plot_ppscore_matrix(pcs_df, covs_to_check, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(pcs_df, 'PCA_0', 'PCA_1', hue_cov='cell_type', style_cov='Batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(covs_to_check) > 0:\n",
    "    dums_covs_df = nuf.dummy_covs_as_needed(pcs_df[list(set(covs_to_check) | \n",
    "                                                        set(covs_target_list))])\n",
    "    nuf.plot_correlation_heatmap(dums_covs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the quantification variation covariates, the PCA components, in 2D with MDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embd_df = nuf.generate_2d_embed_df(pca_df, covs_df)\n",
    "print(f'embd_df shape is {embd_df.shape}')\n",
    "if DEBUG:\n",
    "    display(embd_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', style_cov='Batch')\n",
    "nuf.plot_pair(embd_df, 'LD_1', 'LD_2', hue_cov='cell_type', size_cov='EstimatedNumberofCells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
