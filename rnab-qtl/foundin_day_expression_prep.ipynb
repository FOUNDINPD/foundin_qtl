{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to prep expression data\n",
    "detection, sex check, normalization, and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries and notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from umap import UMAP\n",
    "import ppscore as pps\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "import concurrent.futures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter variables\n",
    "cohort = 'foundin'\n",
    "amp_abbr = 'PP'\n",
    "version = 'amppdv1'\n",
    "day = 'da65'\n",
    "quant_type = 'vst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming\n",
    "cohort_build = f'{cohort}.{day}'\n",
    "\n",
    "# directories\n",
    "wrk_dir = f'/home/jupyter/{cohort}/eqtl'\n",
    "expr_dir = f'{wrk_dir}/expression'\n",
    "info_dir = f'{wrk_dir}/sample_info'\n",
    "\n",
    "# input files\n",
    "src_expression_matrix = f'{expr_dir}/{cohort}.{day}.{quant_type}.genes.hdf5'\n",
    "covariates_file = f'{info_dir}/foundin_rnab_sample_info.csv'\n",
    "feature_ids_exclude_var_file = f'{expr_dir}/{cohort}.{quant_type}.variance.features.exclude.txt'\n",
    "gencode_pkl = f'{expr_dir}/gencode_v29.lncipedia_v5_2_hc.annotation.pkl'\n",
    "\n",
    "# output files\n",
    "umap_covs_file = f'{info_dir}/{cohort_build}.umap.covs.csv'\n",
    "qtnorm_expr_file = f'{expr_dir}/{cohort_build}.norm.hdf5'\n",
    "adj_expr_file = f'{expr_dir}/{cohort_build}.norm.adj.hdf5'\n",
    "tnsrqtl_pheno_file = f'{expr_dir}/{cohort_build}.norm.adj.bed.gz'\n",
    "\n",
    "# constant values\n",
    "min_expr_value = 1\n",
    "max_missing_rate = 0.25\n",
    "min_ppscore = 0.05\n",
    "min_pearson = 0.22\n",
    "\n",
    "autosomes = [str(x) for x in list(range(1,23))]\n",
    "\n",
    "repeated_id_dict = {'PPMI3966B1': 'PPMI3966', 'PPMI3966B2': 'PPMI3966', \n",
    "                    'PPMI3966B3': 'PPMI3966', 'PPMI3966B5': 'PPMI3966',\n",
    "                    'PPMI3966B5E6': 'PPMI3966', 'PPMI3966B5E8': 'PPMI3966'}\n",
    "# to match geno's use PPMI3966 Batch3\n",
    "replace_id_dict = {'PPMI3966B3': 'PPMI3966'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions for detection rates calculations and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_rates(this_df, quant_type, round_percision=1, \n",
    "                              min_expr_value=None):\n",
    "    if min_expr_value is None:\n",
    "        min_expr_value = expr_df.round(round_percision).min().min()\n",
    "\n",
    "    print(f'minimun {quant_type} value is {min_expr_value}')\n",
    "\n",
    "    detected_df = this_df.mask(this_df.round(round_percision) <= min_expr_value, 0)\n",
    "\n",
    "    # calculate the missing counts from the detected df mask\n",
    "    trait_missing_rates = round(detected_df.isin({0}).sum(0)/detected_df.shape[0], 2)\n",
    "    sample_missing_rates = round(detected_df.isin({0}).sum(1)/detected_df.shape[1], 2)\n",
    "\n",
    "    print(f'{len(trait_missing_rates)} features with mean missing \\\n",
    "rate = {trait_missing_rates.mean()}')\n",
    "    print(f'{len(sample_missing_rates)} samples with mean missing \\\n",
    "rate = {sample_missing_rates.mean()}')\n",
    "    return trait_missing_rates, sample_missing_rates\n",
    "\n",
    "def plot_missing_rates(feature_rates, sample_rates):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.distplot(feature_rates.values)\n",
    "    plt.title('Features missingness rates')\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.distplot(sample_rates.values)\n",
    "    plt.title('Samples missingness rates')\n",
    "    plt.show()\n",
    "    \n",
    "def bad_callrate_features(features_missing_rates, max_missing_rate):\n",
    "    bad_call_rates = features_missing_rates[features_missing_rates > max_missing_rate]\n",
    "    print(f'features with bad call rates shape {bad_call_rates.shape}, \\\n",
    "fraction of features with bad rates {bad_call_rates.shape[0]/expr_df.shape[1]}')\n",
    "    return bad_call_rates\n",
    "\n",
    "def subset_well_detected_features(this_df, bad_call_rates):\n",
    "    detected_traits = list(set(this_df.columns)-set(bad_call_rates.index))\n",
    "    this_wd_df = this_df[detected_traits]\n",
    "    print(f'shape of well detected quants {this_wd_df.shape}')\n",
    "    return this_wd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to generate and visualize known and unknow covariates using UMAP and PPScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting umap of traits with covar high lights\n",
    "def plot_umap_clusters(umap_df, hue_cov=None, style_cov=None, size_cov=None):\n",
    "    # umap_plot_file = f'{WRKDIR}/{COHORTBUILD}.umap.residuals.umap.plot.png'\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns_plot = sns.scatterplot(x='x_umap',y='y_umap', \\\n",
    "                               hue=hue_cov, style=style_cov, size=size_cov, \\\n",
    "                               data=umap_df)\n",
    "    plt.xlabel('x-umap')\n",
    "    plt.ylabel('y-umap')\n",
    "    #plt.legend(loc='lower right', prop={'size': 6})\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0,prop={'size': 6})\n",
    "    # plt.savefig(umap_plot_file,format='png',dpi=600,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# small function to generate umap from pandas dataframe, for all features (columns) \\\n",
    "# and return back as dataframe with source index intact\n",
    "def generate_umap_covs_df(this_df, other_covs_df=None, \n",
    "                             rnd_digits=3, merge_input=False):\n",
    "    #run UMAP on the data frame features\n",
    "    umap_results = UMAP(random_state=42).fit_transform(this_df)\n",
    "    umap_df = pd.DataFrame(umap_results,columns=['x_umap','y_umap'], \\\n",
    "                                       index=this_df.index).round(rnd_digits)\n",
    "    if merge_input:\n",
    "        umap_df = umap_df.merge(this_df,left_index=True,right_index=True)\n",
    "    if other_covs_df is not None:\n",
    "        umap_df = umap_df.merge(other_covs_df, how='left', \n",
    "                                left_index=True, right_index=True)\n",
    "    print(f'The dimensions of the umap df and the traits are {umap_df.shape}')\n",
    "    return umap_df \n",
    "\n",
    "# function to iterate over target features and use PPScore to find covarites of interest\n",
    "def pps_predict_targets(this_df, target_list):\n",
    "    covs_to_check = []\n",
    "#     covs_list = ['x_umap', 'y_umap']\n",
    "    for this_cov in target_list:\n",
    "        print(this_cov)\n",
    "        predictors_df = pps.predictors(this_df, this_cov)\n",
    "        # drop anything that has ppscore of zero\n",
    "        predictors_df = predictors_df.loc[predictors_df['ppscore'] > min_ppscore]\n",
    "        display(predictors_df)\n",
    "        covs_to_check.extend(list(predictors_df['x'].values))\n",
    "\n",
    "    print(f'found {len(covs_to_check)} covariates that may preditct target covariates')    \n",
    "    return covs_to_check\n",
    "\n",
    "# plot ppscore matrix \n",
    "def plot_ppscore_matrix(this_df, covs_to_check, cov_targets):\n",
    "    matrix_df = pps.matrix(this_df[(set(covs_to_check) | set(cov_targets))])\n",
    "    matrix_df = matrix_df.loc[matrix_df['ppscore'] > min_ppscore]\n",
    "    print(matrix_df.shape)\n",
    "\n",
    "    matrix_df['ppscore'] = matrix_df['ppscore'].round(2)\n",
    "    plot_matrix_df = matrix_df[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "    print(plot_matrix_df.shape)\n",
    "    # display(plot_matrix_df)\n",
    "\n",
    "    plt.figure(figsize=(plot_matrix_df.shape[0],plot_matrix_df.shape[1])) \n",
    "    sns.heatmap(plot_matrix_df, vmin=0, vmax=1, cmap='Blues', linewidths=0.05, \n",
    "                annot=True, annot_kws={'fontsize':12})\n",
    "    plt.title('PPScore heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "# plot heatmap of Pearson correlation matrix for PPScore covariates\n",
    "def plot_correlation_heatmap(this_df, covs_list : list=None):\n",
    "    sns.set()\n",
    "    cor = this_df.corr(method='pearson')\n",
    "    cor.dropna(how='all', inplace=True)\n",
    "    modified_title = ''\n",
    "    if covs_list is not None:\n",
    "        \n",
    "        limited_cor = cor[covs_list]\n",
    "        cor = limited_cor.loc[(limited_cor['x_umap'].abs() > min_pearson) | \n",
    "                              (limited_cor['y_umap'].abs() > min_pearson)]\n",
    "        modified_title = 'limited'\n",
    "    print(cor.shape)\n",
    "    # sometimes with very unique dummies matrix is to large to plot\n",
    "    if cor.shape[1] < 100:\n",
    "        fig_width = cor.shape[1] if cor.shape[1] > 6 else 6\n",
    "        fig_height = cor.shape[0] if cor.shape[1] > 6 else 6\n",
    "        plt.figure(figsize=(fig_width, fig_height))        \n",
    "        sns.heatmap(cor[(cor > min_pearson) | (cor < -min_pearson)], annot=True, \n",
    "                    annot_kws={\"fontsize\":10}, linewidths=0.05, cmap='Blues')    \n",
    "        plt.title(f'Pearson heatmap of PPScore covariates {modified_title}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('too many covariates to plot')\n",
    "\n",
    "# function to one-hot encode the categorical covariates and merge with continuous ones    \n",
    "def dummy_covs_as_needed(this_df):\n",
    "    temp_df = this_df.copy()\n",
    "    cats_df = temp_df.select_dtypes(include=['object'])\n",
    "    print(f'categoricals shape {cats_df.shape}')\n",
    "    if cats_df.shape[1] > 0:\n",
    "        dums_df = pd.get_dummies(cats_df)\n",
    "        print(f'one-hot encoded categoricals shape {dums_df.shape}')\n",
    "\n",
    "        temp_df = temp_df.merge(dums_df, how='inner', left_index=True, right_index=True)\n",
    "        print(f'new covs df shape {temp_df.shape}')\n",
    "    return temp_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small function to plot before and after of transform based on named feature,\n",
    "# or if a feature isn't specified then one pull at random\n",
    "def plot_trnsfrm_effect_example(before_df, after_df, feature_id=None,\n",
    "                                bf_label='quantile transformed', \n",
    "                                af_label='quantile transformed and covariate adjusted'):\n",
    "    # if no feature ID provided get randome one\n",
    "    if feature_id is None:\n",
    "        feature_id = random.sample(list(after_df.columns), 1)[0]\n",
    "    \n",
    "    sns.distplot(before_df[feature_id])\n",
    "    plt.title(f'{feature_id} {bf_label}')\n",
    "    plt.show()\n",
    "    sns.distplot(after_df[feature_id])\n",
    "    plt.title(f'{feature_id} {af_label}')\n",
    "    plt.show()\n",
    "    sns.scatterplot(x=before_df[feature_id], y=after_df[feature_id])\n",
    "    plt.title(f'{feature_id}')\n",
    "    plt.xlabel(f'{bf_label}')\n",
    "    plt.ylabel(f'{af_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small function to perform the quantile transform on a pandas dataframe\n",
    "def quantile_transform_df(this_df : pd.DataFrame):\n",
    "    transformedX = preprocessing.quantile_transform(this_df, axis=0, copy=True, \n",
    "                                                    output_distribution='normal')\n",
    "    transformed_df = pd.DataFrame(data=transformedX, columns=this_df.columns, \n",
    "                                 index=this_df.index)  \n",
    "    return transformed_df\n",
    "\n",
    "# exclude low variance genes from covariate generation\n",
    "def exclude_low_var_features(this_df: pd.DataFrame, quartile_to_drop: str ='25%', \n",
    "                             known_feature_to_drop=None):\n",
    "    quants_vars = this_df.var() \n",
    "    print(quants_vars.describe())\n",
    "    # drop genes within the lower quartile of variance\n",
    "    min_variance = quants_vars.describe()['25%']\n",
    "    # min_variance = quants_vars.describe()['50%']\n",
    "    keep = quants_vars[quants_vars > min_variance]\n",
    "    if known_feature_to_drop is not None:\n",
    "        keep_ids = set(keep.index) - set(known_feature_to_drop)\n",
    "    else:\n",
    "        keep_ids = set(keep.index)\n",
    "    quants_wd_var_df = this_df[keep_ids]\n",
    "    print(f'shape of the features to keep {keep.shape}')\n",
    "    print(f'shape of input features df {this_df.shape}')\n",
    "    print(f'shape of variance fatures df {quants_wd_var_df.shape}')\n",
    "    return quants_wd_var_df\n",
    "\n",
    "# function to fit linear model to covariates and calculate the standardized residuals\n",
    "def covariate_residuals(traits_df, covars_df):\n",
    "    lm = LinearRegression(n_jobs=16)\n",
    "    residuals_df = traits_df.copy()\n",
    "    covar_scores_by_trait = {}\n",
    "\n",
    "    for trait in traits_df:\n",
    "            model = lm.fit(covars_df, traits_df[trait])\n",
    "            covar_scores_by_trait[trait] = model.score(covars_df,traits_df[trait])\n",
    "            model_predicted = model.predict(covars_df)\n",
    "            residuals_df[trait] = stats.zscore(traits_df[trait] - model_predicted)\n",
    "            \n",
    "#     # We can use a with statement to ensure threads are cleaned up promptly\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as ppe:\n",
    "#         # Start the load operations and mark each future with its URL\n",
    "#         future_to_residual = {executor.submit(compute_residuals, trait): trait for trait in traits_df}\n",
    "#         for future in concurrent.futures.as_completed(future_to_residual):\n",
    "#             covar_scores_by_trait[trait], residuals_df[trait] = future_to_residual[future]\n",
    "\n",
    "    # grab the covariates model scores\n",
    "    covar_scores_by_trait_df = pd.DataFrame.from_dict(covar_scores_by_trait,\n",
    "                                                      columns=['score'],\n",
    "                                                      orient='index').round(3)\n",
    "    covar_scores_by_trait_df.index.name = 'geneID'\n",
    "    return residuals_df, covar_scores_by_trait_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input output functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small function to save hdf file\n",
    "def write_df_to_hdf(this_df, file_name, key='quants', mode='w'):\n",
    "    this_df.to_hdf(file_name, key=key, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load covariates files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df = pd.read_csv(covariates_file, index_col=0)\n",
    "print(covs_df.shape)\n",
    "# display(covs_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert the gencode gtf to easier to read format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if the gencode pickle files already exist don't regenerate it\n",
    "# if not os.path.isfile(gencode_pkl):\n",
    "#     this_cmd = f'gtf2csv --gtf {gencode_gtf} -m pkl -t $(nproc) -o {gencode_pkl}'\n",
    "\n",
    "#     print(this_cmd)\n",
    "#     !{this_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the gencode annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gencode_df = pd.read_pickle(gencode_pkl)\n",
    "print(gencode_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "expr_df = pd.read_hdf(src_expression_matrix, index_col=0)\n",
    "print(expr_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split assayid into meta data bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    id_parts = expr_df.index.str.split('_', expand=True).to_frame()\n",
    "id_parts.columns = ['assay', 'sampleid', 'cdi', 'day', 'version']\n",
    "id_parts['assayid'] = expr_df.index\n",
    "print(id_parts.shape)\n",
    "# display(id_parts.sample(5))\n",
    "# id_parts['sampleid'].replace(repeated_id_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### capture the assayid to wgsid for formatting phenotypes for use with wgs genotypes later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = id_parts[['sampleid', 'assayid']]\n",
    "id_map['sampleid'].replace(replace_id_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check to see if missing covariate info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any unexpected samples; ie probably name frmt issue\n",
    "set(expr_df.index) - set(covs_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(id_parts['sampleid']) - set(covs_df['sampleid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check expected sex of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vawter MP, Evans S, Choudary P et al. Gender-specific gene expression in \n",
    "#post-mortem human brain: localization to sex chromosomes. \n",
    "#Neuropsychopharmacology 2004;29:373â€“84.\n",
    "\n",
    "sex_specific_genes = ['XIST','RPS4Y1','RPS4Y2','KDM5D','UTY','DDX3Y','USP9Y']\n",
    "sex_genes = gencode_df.loc[gencode_df['gene_name'].isin(sex_specific_genes)]\n",
    "print(sex_genes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_genes['seqname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check sex of samples against reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_genes_present = list(set(sex_genes['gene_id'].values) & set(expr_df.columns))\n",
    "expr_sex_df = expr_df[sex_genes_present]\n",
    "print(expr_sex_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sex_umap_df = generate_umap_covs_df(expr_sex_df, covs_df)\n",
    "plot_umap_clusters(sex_umap_df, hue_cov='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sex_umap_df.loc[(sex_umap_df['x_umap'] > 0) & (sex_umap_df['sex'] == 'Female')].shape)\n",
    "print(sex_umap_df.loc[(sex_umap_df['x_umap'] < 0) & (sex_umap_df['sex'] == 'Male')].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### double check the age range to make sure no young subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_df['age_at_baseline'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop the know bad samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(bad_samples.index) & set(expr_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now drop the know bad samples\n",
    "# bad_samples.head()\n",
    "# print(expr_df.shape)\n",
    "# expr_df = expr_df.loc[~expr_df.index.isin(bad_samples.index)]\n",
    "# print(expr_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate, plot detection rates and subset well detected expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trait_miss_rates, sample_miss_rates = calculate_detection_rates(expr_df, quant_type)\n",
    "plot_missing_rates(trait_miss_rates, sample_miss_rates)\n",
    "bad_call_rate_features = bad_callrate_features(trait_miss_rates, max_missing_rate)\n",
    "quants_wd_df = subset_well_detected_features(expr_df, bad_call_rate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize the full dataset using quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "traits_qtnorm_df = quantile_transform_df(quants_wd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trnsfrm_effect_example(expr_df, traits_qtnorm_df,\n",
    "                            bf_label=quant_type, \n",
    "                            af_label='quantile transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save quantile standardized, well detected data for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df_to_hdf(traits_qtnorm_df, qtnorm_expr_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load known exclude features, if specified and present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_exclude_features = pd.read_csv(feature_ids_exclude_var_file)\n",
    "known_exclude_feature_ids = known_exclude_features['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude low variance genes from covariate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_var_df = exclude_low_var_features(traits_qtnorm_df, \n",
    "                                         known_feature_to_drop=known_exclude_feature_ids)\n",
    "# quants_var_df = exclude_low_var_features(traits_qtnorm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate unknown covariates and see if know covariates are source of variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = generate_umap_covs_df(quants_var_df, covs_df)\n",
    "covs_target_list = ['x_umap', 'y_umap']\n",
    "covs_to_check = pps_predict_targets(umap_df, covs_target_list)\n",
    "plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "umap_dums_covs_df = dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                  set(covs_target_list))])\n",
    "plot_correlation_heatmap(umap_dums_covs_df)\n",
    "plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot umap of with known covariates of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_clusters(umap_df, hue_cov='Batch', size_cov='LateneuronProgenitor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_clusters(umap_df, hue_cov='Culture_Media_iPSC', size_cov='LateneuronProgenitor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep created covars and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the covariates\n",
    "umap_covs_df = quantile_transform_df(umap_df[covs_target_list])\n",
    "# now save the covariates\n",
    "umap_covs_df.to_csv(umap_covs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### covariate adjust the normalized data by the covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see in df's have same indices\n",
    "if not traits_qtnorm_df.index.equals(umap_covs_df.index):\n",
    "    print('indices are not equal re-index')\n",
    "    umap_covs_df.reindex(traits_qtnorm_df.index)\n",
    "    \n",
    "traits_qtnorm_df.index.equals(umap_covs_df.index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "residuals_df, cov_scores_df = covariate_residuals(traits_qtnorm_df, umap_covs_df)\n",
    "\n",
    "#take a peek at the data\n",
    "print(residuals_df.shape)\n",
    "print(cov_scores_df.shape)\n",
    "\n",
    "# print(cov_scores_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of the covariates model scores\n",
    "print(cov_scores_df.describe())\n",
    "# look at the distribution of covariate model scores, \n",
    "# ie get a sense any gene driven by covariates\n",
    "sns.set()\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.distplot(cov_scores_df['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save quantile normalized and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "residuals_df.to_hdf(adj_expr_file, key='expression', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take a look at the normalized and covariate adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trnsfrm_effect_example(traits_qtnorm_df, residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find gene with largest score\n",
    "large_adj_trait = cov_scores_df.loc[cov_scores_df['score'] == max(cov_scores_df['score'])]\n",
    "print(large_adj_trait)\n",
    "large_adj_traid_id = large_adj_trait.index.values[0]\n",
    "\n",
    "# spot check same gene with largest adjustment effect\n",
    "plot_trnsfrm_effect_example(traits_qtnorm_df, residuals_df, large_adj_traid_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what are the post normalization and covariate adjusted umap variables correlated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_df = generate_umap_covs_df(residuals_df, covs_df)\n",
    "covs_to_check = pps_predict_targets(umap_df, covs_target_list)\n",
    "plot_ppscore_matrix(umap_df, covs_to_check, covs_target_list)\n",
    "umap_dums_covs_df = dummy_covs_as_needed(umap_df[(set(covs_to_check) | \n",
    "                                                  set(covs_target_list))])\n",
    "plot_correlation_heatmap(umap_dums_covs_df)\n",
    "plot_correlation_heatmap(umap_dums_covs_df, covs_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_clusters(umap_df, hue_cov='Batch', size_cov='LateneuronProgenitor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### since switching to tensorQTL can just use one large transcriptome pheno bed instead of per chrom pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get gene annots for present features\n",
    "gencode_present_df = gencode_df.loc[gencode_df['gene_id'].isin(residuals_df.columns)]\n",
    "# tensorQTL pheno bed is rows = features and columns = samples\n",
    "# where first four columns are chr, start, end, phenotype_id, then sample1 ... sampleN\n",
    "\n",
    "# create dict for renaming columns (samples) from assayid to geno_id\n",
    "sample_col_dict = id_map.set_index('assayid').to_dict()['sampleid']\n",
    "\n",
    "# transpose the residuals df from sample x feature to feature x sample\n",
    "tresiduals_df = residuals_df.transpose()\n",
    "\n",
    "# modify annots\n",
    "genes_df = gencode_present_df[['seqname', 'start', 'end', 'gene_id', 'strand']].copy()\n",
    "genes_df.rename(columns={'seqname': 'chr', 'start': 'fstart', \n",
    "                         'end': 'fend'}, inplace=True)\n",
    "# for tensorQTL 'end' column is TSS so set appropriately\n",
    "genes_df['end'] = np.where(genes_df['strand'] == '+',  genes_df['fstart'], genes_df['fend'])\n",
    "genes_df['start'] = genes_df['end'] - 1\n",
    "# there is a feature per transcript, so can be multiple entries per gene, so just keep longest\n",
    "genes_df['length'] = genes_df['fend'] - genes_df['fstart']\n",
    "genes_df.sort_values(by=['gene_id', 'length'], inplace=True, ascending=False)\n",
    "print(genes_df.shape)\n",
    "genes_df.drop_duplicates(subset=['gene_id'], keep='first', inplace=True, ignore_index=True)\n",
    "genes_df.set_index('gene_id', inplace=True, drop=False)\n",
    "genes_df = genes_df.reindex(tresiduals_df.index)\n",
    "\n",
    "# insert the feature annots\n",
    "tresiduals_df.insert( 0, column='chr', value=genes_df['chr'])\n",
    "tresiduals_df.insert( 1, column='start', value=genes_df['start'])\n",
    "tresiduals_df.insert( 2, column='end', value=genes_df['end'])\n",
    "tresiduals_df.insert( 3, column='phenotype_id', value=genes_df['gene_id'])\n",
    "\n",
    "# now rename sample ids in columns\n",
    "tresiduals_df.rename(columns=sample_col_dict, inplace=True)\n",
    "\n",
    "tresiduals_df.to_csv(tnsrqtl_pheno_file, index=False, sep='\\t', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
